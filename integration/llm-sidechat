#!/bin/sh
''''exec "$HOME/.local/share/uv/tools/llm/bin/python3" "$0" "$@" # '''
"""
llm-sidechat - Terminal AI Assistant for Terminator

A Terminator-integrated AI assistant that provides:
- Automatic Exec terminal creation
- Terminal content capture and analysis
- Command execution with approval
- Watch Mode for proactive monitoring
- Context squashing to manage token limits
- Streaming responses with markdown rendering
- Robust error handling and recovery

Inspired by TmuxAI but designed for Terminator terminal emulator.

Author: c0ffee0wl
License: GPL v2 only
"""

import sys

import llm
from llm.cli import load_template, resolve_fragments, FragmentNotFound

# Add system site-packages to path for dbus and other system-only packages
# (Must be AFTER llm imports to avoid typing_extensions conflicts)
sys.path.insert(0, '/usr/lib/python3/dist-packages')
import os
import re
import time
import asyncio
import threading
import dbus
import fcntl
import signal
import atexit
from pathlib import Path
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.text import Text
from typing import List, Optional, Tuple, Dict


class PromptDetector:
    """Detect shell prompts to determine command completion"""

    # Common prompt patterns
    BASH_PROMPT = re.compile(r'[\$#]\s*$')
    ZSH_PROMPT = re.compile(r'[%❯→➜]\s*$')
    # Kali two-line prompt (with optional error indicator like "1 ⨯")
    KALI_PROMPT = re.compile(r'┌──.*\n└─[\$#]\s*(?:\d+\s*[⨯✗×])?\s*$')
    # Generic fallback
    GENERIC_PROMPT = re.compile(r'^[\w@\-]+[:#\$>]\s*$', re.MULTILINE)

    @staticmethod
    def detect_prompt(text: str) -> bool:
        """Check if text ends with a shell prompt"""
        if not text or len(text.strip()) == 0:
            return False

        # Get last few lines
        lines = text.strip().split('\n')
        last_line = lines[-1] if lines else ""
        last_two = '\n'.join(lines[-2:]) if len(lines) >= 2 else last_line

        # Check patterns
        if PromptDetector.BASH_PROMPT.search(last_line):
            return True
        if PromptDetector.ZSH_PROMPT.search(last_line):
            return True
        if PromptDetector.KALI_PROMPT.search(last_two):
            return True
        if PromptDetector.GENERIC_PROMPT.search(last_line):
            return True

        return False


# Common TUI applications that shouldn't use stability detection
TUI_COMMANDS = {
    'htop', 'top', 'btop', 'glances',  # System monitors
    'vim', 'vi', 'nvim', 'nano', 'emacs', 'helix',  # Editors
    'less', 'more', 'most',  # Pagers
    'watch',  # Periodic command execution
    'tmux', 'screen',  # Terminal multiplexers
    'ncdu', 'mc', 'ranger', 'nnn',  # File managers
    'tig', 'lazygit',  # Git TUIs
    'k9s', 'kubectl',  # Kubernetes TUIs (when in interactive mode)
    'docker', 'lazydocker',  # Docker TUIs (when in interactive mode)
    'htop', 'iotop', 'iftop', 'nethogs',  # Various monitors
    'alsamixer', 'pulsemixer',  # Audio mixers
    'mutt', 'neomutt',  # Email clients
    'weechat', 'irssi',  # IRC clients
    'cmus', 'ncmpcpp',  # Music players
    'lynx', 'w3m', 'links',  # Web browsers
}

# Pattern to detect special keys that should be routed to keypress handler
# Matches function keys, navigation keys, and key combinations
SPECIAL_KEY_PATTERN = re.compile(
    r'^(F[1-9]|F1[0-2]|Enter|Return|Escape|Esc|Tab|Backspace|Delete|Insert|'
    r'Home|End|PageUp|PageDown|Up|Down|Left|Right|Space|'
    r'Ctrl\+[A-Z]|Alt\+[A-Za-z]+|Shift\+Tab)$',
    re.IGNORECASE
)


def is_tui_command(command: str) -> bool:
    """
    Detect if a command is a TUI application that continuously updates
    or waits for input.

    Args:
        command: Full command string (e.g., "htop -d 5")

    Returns:
        True if command is a known TUI application
    """
    # Extract the base command (first word)
    base_cmd = command.strip().split()[0] if command.strip() else ""

    # Remove path if present (e.g., /usr/bin/htop -> htop)
    base_cmd = os.path.basename(base_cmd)

    return base_cmd in TUI_COMMANDS


class TerminatorSidechatSession:
    """Main sidechat session manager for Terminator"""

    def __init__(self, model_name: Optional[str] = None):
        self.console = Console()

        # Initialize shutdown state and lock file handle
        self._shutdown_initiated = False
        self.lock_file = None

        # Acquire instance lock FIRST (before any other initialization)
        self._acquire_instance_lock()

        # Register shutdown handlers EARLY (before creating resources)
        self._register_shutdown_handlers()

        self.model_name = model_name or self._get_default_model()

        try:
            self.model = llm.get_model(self.model_name)
        except Exception as e:
            self.console.print(f"[red]Error loading model '{self.model_name}': {e}[/]")
            self.console.print("[yellow]Available models:[/]")
            for model in llm.get_models():
                self.console.print(f"  - {model.model_id}")
            sys.exit(1)

        self.conversation = llm.Conversation(model=self.model)

        # Store system prompt separately for reuse
        try:
            template = load_template("terminator-sidechat")
            # Use system if available, otherwise use prompt
            self.system_prompt = template.system or template.prompt
            if not self.system_prompt:
                raise ValueError("Template has no system or prompt field")
        except Exception as e:
            self.console.print(f"[yellow]⚠ Could not load terminator-sidechat template: {e}[/]")
            self.console.print("[yellow]Using basic system prompt. Install template with: ./install-llm-tools.sh[/]")
            self.system_prompt = "You are an AI terminal assistant. Provide commands in ```bash blocks."

        # Store original system prompt for context squashing
        # This prevents infinite growth when squashing multiple times
        self.original_system_prompt = self.system_prompt

        # Terminal tracking
        self.chat_terminal_uuid = None
        self.exec_terminal_uuid = None

        # Context management (like tmuxai)
        self.max_context_size = 100000  # tokens
        self.context_squash_threshold = 0.8  # 80%

        # Watch mode (thread-safe)
        self.watch_mode = False
        self.watch_goal = None
        self.watch_thread = None
        self.watch_interval = 5  # seconds
        self.watch_lock = threading.Lock()
        self.event_loop = None

        # Intelligent capture timing configuration
        self.capture_config = {
            'initial_delay': 0.3,        # Initial wait before first capture (seconds)
            'poll_interval': 0.2,        # Starting poll interval (seconds)
            'max_poll_interval': 1.0,    # Maximum poll interval (seconds)
            'backoff_factor': 1.3,       # Exponential backoff multiplier
            'stability_checks': 3,       # Consecutive matches needed for stability
            'max_wait': 3.0,             # Total timeout (seconds)
            'min_wait_before_stability': 0.5,  # Minimum wait before allowing stability detection
        }

        # Plugin and D-Bus connections
        self.plugin = None
        self.dbus_service = None

    def _acquire_instance_lock(self):
        """
        Ensure only one sidechat instance per user session.
        Uses file locking with automatic cleanup on process exit.
        """
        # Use runtime directory for lock file (XDG_RUNTIME_DIR or /tmp)
        runtime_dir = os.environ.get('XDG_RUNTIME_DIR', '/tmp')
        lock_path = Path(runtime_dir) / 'llm-sidechat.lock'

        try:
            # Open lock file (create if doesn't exist)
            self.lock_file = open(lock_path, 'w')

            # Try to acquire exclusive lock (non-blocking)
            fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

            # Write PID for debugging (optional but helpful)
            self.lock_file.write(f"{os.getpid()}\n")
            self.lock_file.flush()

        except BlockingIOError:
            # Lock is held by another instance
            self.console.print("[red]Error: Another sidechat instance is already running[/]")
            self.console.print("[yellow]Only one sidechat session can run at a time.[/]")
            self.console.print(f"[yellow]Lock file: {lock_path}[/]")

            # Try to read PID from lock file
            try:
                with open(lock_path, 'r') as f:
                    pid = f.read().strip()
                    if pid:
                        self.console.print(f"[yellow]Existing instance PID: {pid}[/]")
            except:
                pass

            sys.exit(1)

        except Exception as e:
            self.console.print(f"[red]Error acquiring lock: {e}[/]")
            sys.exit(1)

    def _release_instance_lock(self):
        """Release the instance lock (automatic on process exit, but explicit is better)"""
        if self.lock_file:
            try:
                fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                self.lock_file.close()
                self.lock_file = None
            except Exception:
                pass  # Lock will be released by kernel anyway

    def _register_shutdown_handlers(self):
        """Register signal handlers and atexit hook for cleanup"""
        # Register atexit fallback (runs on normal exit)
        atexit.register(self._shutdown)

        # Register signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, self._signal_handler)  # kill command
        signal.signal(signal.SIGHUP, self._signal_handler)   # Terminal closed

    def _signal_handler(self, signum, frame):
        """Handle termination signals"""
        signal_names = {
            signal.SIGINT: "SIGINT (Ctrl+C)",
            signal.SIGTERM: "SIGTERM",
            signal.SIGHUP: "SIGHUP (terminal closed)"
        }
        signal_name = signal_names.get(signum, f"signal {signum}")

        self.console.print(f"\n[yellow]Received {signal_name}, shutting down...[/]")
        self._shutdown()
        sys.exit(0)  # Exit cleanly

    def _shutdown(self):
        """
        Unified shutdown method - called by signal handlers, atexit, or manual exit.
        Idempotent - safe to call multiple times.
        """
        # Prevent double-cleanup
        if self._shutdown_initiated:
            return
        self._shutdown_initiated = True

        try:
            # STEP 1: Stop watch mode (most critical - prevents new threads)
            if hasattr(self, 'watch_mode') and self.watch_mode:
                try:
                    with self.watch_lock:
                        self.watch_mode = False
                        if self.event_loop:
                            try:
                                self.event_loop.call_soon_threadsafe(self.event_loop.stop)
                            except Exception:
                                pass

                    # Wait for watch thread to finish (with timeout)
                    if self.watch_thread and self.watch_thread.is_alive():
                        self.watch_thread.join(timeout=2.0)
                except Exception:
                    # Don't let watch mode cleanup prevent other cleanup
                    pass

            # STEP 2: Clear plugin cache (if available)
            if hasattr(self, 'plugin_dbus'):
                try:
                    self.plugin_dbus.clear_cache()
                except Exception:
                    pass

            # STEP 3: Close D-Bus connections (graceful disconnect)
            # D-Bus connections don't need explicit cleanup in Python - garbage collected
            # But we can dereference them to signal intent
            if hasattr(self, 'dbus_service'):
                self.dbus_service = None
            if hasattr(self, 'plugin_dbus'):
                self.plugin_dbus = None

            # STEP 4: Release instance lock (most important)
            self._release_instance_lock()

            # STEP 5: Save conversation state (if needed)
            # llm library auto-saves, but we can explicitly flush here
            if hasattr(self, 'conversation'):
                try:
                    # Force any pending writes to complete
                    # llm Conversation doesn't have explicit save(), it auto-saves
                    pass
                except Exception:
                    pass

        except Exception as e:
            # Ensure we log errors but don't prevent shutdown
            try:
                self.console.print(f"[yellow]Warning during shutdown: {e}[/]")
            except:
                # If console fails, write to stderr
                print(f"Warning during shutdown: {e}", file=sys.stderr)

    def _get_default_model(self) -> str:
        """Get default model from llm configuration"""
        try:
            return llm.get_default_model()
        except Exception:
            return "azure/gpt-4.1-mini"

    def _normalize_uuid(self, uuid_value) -> str:
        """Normalize UUID to Python string (ensures dbus.String -> str conversion)"""
        if uuid_value is None or uuid_value == '':
            return None
        # Explicitly convert to Python str (handles dbus.String)
        return str(uuid_value)

    def _reconnect_dbus(self) -> bool:
        """Attempt to reconnect to Terminator D-Bus"""
        try:
            bus = dbus.SessionBus()

            # Discover actual Terminator service name (includes UUID suffix)
            service_name = None
            for name in bus.list_names():
                if name.startswith('net.tenshu.Terminator2'):
                    service_name = name
                    break

            if not service_name:
                service_name = 'net.tenshu.Terminator2'  # Fallback for older versions

            self.dbus_service = bus.get_object(service_name, '/net/tenshu/Terminator2')
            return True
        except Exception as e:
            self.console.print(f"[red]D-Bus reconnection failed: {e}[/]")
            return False

    def _check_dbus_connection(self) -> bool:
        """Verify D-Bus is still connected"""
        try:
            # Try a simple D-Bus operation
            self.dbus_service.get_terminals()
            return True
        except Exception:
            return False

    def _connect_to_terminator(self):
        """Connect to Terminator and plugin via D-Bus"""
        # Connect to Terminator's main D-Bus service for terminal management
        if not self._reconnect_dbus():
            self.console.print("[red]Error: Could not connect to Terminator D-Bus service[/]")
            self.console.print("Ensure Terminator is running with D-Bus enabled")
            sys.exit(1)

        # Connect to plugin's D-Bus service for terminal content/commands
        if not self._connect_to_plugin_dbus():
            self.console.print("[red]Error: Plugin D-Bus service not available[/]")
            self.console.print("Ensure TerminatorSidechatPlugin is:")
            self.console.print("  1. Installed in ~/.config/terminator/plugins/")
            self.console.print("  2. Enabled in Terminator Preferences > Plugins")
            self.console.print("  3. Terminator has been restarted after enabling")
            sys.exit(1)

    def _connect_to_plugin_dbus(self) -> bool:
        """Connect to plugin's D-Bus service"""
        try:
            bus = dbus.SessionBus()
            self.plugin_dbus = bus.get_object(
                'net.tenshu.Terminator2.Sidechat',
                '/net/tenshu/Terminator2/Sidechat'
            )

            # Check plugin version for diagnostics
            try:
                version = self.plugin_dbus.get_plugin_version()
                self.console.print(f"[dim]Plugin version: {version}[/dim]")
                if "vadjustment" not in version.lower():
                    self.console.print("[yellow]⚠ Plugin is outdated! Restart Terminator to load new version.[/yellow]")
                    self.console.print("[yellow]  Run: killall -9 terminator && terminator &[/yellow]")
            except Exception:
                self.console.print("[yellow]⚠ Plugin version check failed (old plugin running)[/yellow]")
                self.console.print("[yellow]  Restart Terminator: killall -9 terminator && terminator &[/yellow]")

            return True
        except Exception as e:
            self.console.print(f"[yellow]Plugin D-Bus connection failed: {e}[/]")
            return False

    def _check_plugin_available(self) -> bool:
        """Verify plugin D-Bus service is available"""
        try:
            # Try a simple D-Bus call to check if service is alive
            self.plugin_dbus.get_focused_terminal_uuid()
            return True
        except Exception:
            return False

    def _reconnect_plugin(self) -> bool:
        """Attempt to reconnect to plugin D-Bus service"""
        return self._connect_to_plugin_dbus()

    def setup_terminals(self):
        """Auto-create Exec terminal with retry logic"""
        self.console.print("[cyan]Setting up terminals...[/]")

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # Check D-Bus connection
                if not self._check_dbus_connection():
                    if not self._reconnect_dbus():
                        raise Exception("D-Bus reconnection failed")

                # Get current (Chat) terminal UUID
                focused_terminal = self.dbus_service.get_focused_terminal()
                if not focused_terminal:
                    raise Exception("No terminal is currently focused. Please focus a terminal and try again.")
                self.chat_terminal_uuid = self._normalize_uuid(focused_terminal)

                # Check if exactly one other pane exists (besides chat terminal)
                try:
                    self.console.print(f"[dim]Checking for existing panes (chat UUID: {self.chat_terminal_uuid[:8]}...)[/dim]")
                    terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
                    self.console.print(f"[dim]Found {len(terminals)} terminal(s) in current window[/dim]")

                    chat_uuid_normalized = self._normalize_uuid(self.chat_terminal_uuid)

                    # Filter out chat terminal
                    other_terminals = [t for t in terminals if self._normalize_uuid(t['uuid']) != chat_uuid_normalized]

                    if len(other_terminals) == 1:
                        # Exactly one other pane exists - offer to use it
                        existing_pane = other_terminals[0]
                        pane_title = existing_pane.get('title', 'Untitled')
                        self.console.print(f"[yellow]Found existing terminal:[/] {pane_title}")

                        use_existing = Confirm.ask("Use this terminal as Exec pane?", default=True)

                        if use_existing:
                            self.exec_terminal_uuid = self._normalize_uuid(existing_pane['uuid'])
                            self.console.print(f"[green]✓[/] Chat terminal: {self.chat_terminal_uuid[:8]}...")
                            self.console.print(f"[green]✓[/] Exec terminal (existing): {self.exec_terminal_uuid[:8]}...")
                            return  # Success - using existing terminal
                except dbus.exceptions.DBusException as e:
                    # D-Bus specific errors (method not found, connection issues, etc.)
                    error_msg = str(e)
                    if 'Unknown method' in error_msg or 'does not exist' in error_msg:
                        self.console.print("[red]ERROR: Plugin method 'get_terminals_in_same_window' not found![/]")
                        self.console.print("[red]Please restart Terminator to load the updated plugin.[/red]")
                    else:
                        self.console.print(f"[red]D-Bus error enumerating terminals: {e}[/]")
                    self.console.print("[yellow]Creating new Exec terminal as fallback...[/]")
                except Exception as e:
                    # Other unexpected errors
                    self.console.print(f"[red]Unexpected error ({type(e).__name__}): {e}[/]")
                    self.console.print("[yellow]Creating new Exec terminal as fallback...[/]")

                # Split vertically to create Exec terminal (to the right)
                exec_uuid = self.dbus_service.vsplit(
                    self.chat_terminal_uuid,
                    dbus.Dictionary({
                        'title': 'Sidechat: Exec'
                    }, signature='ss')
                )
                if str(exec_uuid).startswith('ERROR'):
                    raise Exception(f"Failed to split terminal: {exec_uuid}")
                self.exec_terminal_uuid = self._normalize_uuid(exec_uuid)

                self.console.print(f"[green]✓[/] Chat terminal: {self.chat_terminal_uuid[:8]}...")
                self.console.print(f"[green]✓[/] Exec terminal: {self.exec_terminal_uuid[:8]}...")
                return  # Success

            except Exception as e:
                if attempt < max_retries - 1:
                    self.console.print(f"[yellow]Retry {attempt+1}/{max_retries}: {e}[/]")
                    time.sleep(1)
                else:
                    self.console.print(f"[red]Failed to setup terminals after {max_retries} attempts: {e}[/]")
                    sys.exit(1)

    def _verify_exec_terminal(self) -> bool:
        """Check if exec terminal still exists"""
        try:
            terminals = self.plugin_dbus.get_all_terminals_metadata()

            # DEBUG: Show what we're comparing
            self.console.print(f"[yellow]DEBUG: Looking for exec UUID:[/] {repr(self.exec_terminal_uuid)} (type: {type(self.exec_terminal_uuid).__name__})")
            self.console.print(f"[yellow]DEBUG: Plugin returned {len(terminals)} terminals[/]")
            for t in terminals:
                self.console.print(f"[yellow]  - {repr(t['uuid'])} (type: {type(t['uuid']).__name__}) | Title: {t.get('title', 'N/A')}[/]")
                if t['uuid'] == self.exec_terminal_uuid:
                    self.console.print(f"[green]    ✓ EXACT MATCH![/]")

            # Normalize both sides for comparison
            exec_uuid_normalized = self._normalize_uuid(self.exec_terminal_uuid)
            return any(self._normalize_uuid(t['uuid']) == exec_uuid_normalized for t in terminals)
        except Exception as e:
            self.console.print(f"[red]DEBUG: Verification error: {e}[/]")
            return False

    def _recreate_exec_terminal(self) -> bool:
        """Recreate exec terminal if closed"""
        try:
            self.console.print("[yellow]Recreating Exec terminal...[/]")

            # Get current focused terminal
            focused_terminal = self.dbus_service.get_focused_terminal()
            if not focused_terminal:
                raise Exception("No terminal is currently focused. Cannot recreate Exec terminal.")
            current_uuid = str(focused_terminal)

            # Create new exec terminal (split to the right)
            exec_uuid = self.dbus_service.vsplit(
                current_uuid,
                dbus.Dictionary({'title': 'Sidechat: Exec (Restored)'}, signature='ss')
            )
            if str(exec_uuid).startswith('ERROR'):
                raise Exception(f"Failed to split terminal: {exec_uuid}")

            self.exec_terminal_uuid = self._normalize_uuid(exec_uuid)
            self.console.print(f"[green]✓[/] Exec terminal restored: {exec_uuid[:8]}...")
            return True

        except Exception as e:
            self.console.print(f"[red]Failed to recreate exec terminal: {e}[/]")
            return False

    def intelligent_capture_with_stability(self, terminal_uuid, max_wait=None):
        """
        Capture terminal content with adaptive polling and stability detection.
        Waits for content to stop changing before returning.

        Args:
            terminal_uuid: Terminal to capture
            max_wait: Maximum wait time in seconds (uses config default if None)

        Returns:
            Tuple of (content, timed_out)
        """
        if max_wait is None:
            max_wait = self.capture_config['max_wait']

        # Get configuration
        initial_delay = self.capture_config['initial_delay']
        poll_interval = self.capture_config['poll_interval']
        max_poll_interval = self.capture_config['max_poll_interval']
        backoff_factor = self.capture_config['backoff_factor']
        stability_checks = self.capture_config['stability_checks']

        # Calculate max attempts based on timing
        max_attempts = int(max_wait / poll_interval) + 5

        # Initial delay for command to start executing
        time.sleep(initial_delay)

        # Track elapsed time for minimum wait enforcement
        start_time = time.time()

        previous_content = None
        stable_count = 0
        attempt = 0
        current_interval = poll_interval

        # Spinner animation characters
        spinner_chars = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]

        while attempt < max_attempts:
            # Capture current content
            try:
                current_content = self.plugin_dbus.capture_terminal_content(
                    terminal_uuid, -1
                )

                # DIAGNOSTIC: Log what we're getting
                if attempt == 0:
                    dbg_len = len(current_content) if current_content else 0
                    self.console.print(f"[dim]Initial capture: {dbg_len} chars[/dim]", end="\r")

            except Exception as e:
                # Plugin error, give up
                self.console.print(f"[red]Capture error: {e}[/red]")
                return ("", True)

            # Check for stability with enhanced validation
            elapsed = time.time() - start_time
            min_wait = self.capture_config.get('min_wait_before_stability', 0.5)

            if current_content == previous_content:
                stable_count += 1

                # Apply minimum wait before allowing stability detection
                if elapsed < min_wait:
                    # Too early - reset stability even if content matches
                    stable_count = 0
                    previous_content = current_content
                    # Show why we're not accepting stability yet
                    print(f"\r⏱  Too early for stability ({elapsed:.1f}s < {min_wait}s)   ", end="", flush=True)
                elif stable_count >= stability_checks:
                    # Content appears stable - validate with size heuristic
                    content_len = len(current_content) if current_content else 0

                    # If content is suspiciously small (< 400 chars), require extra confirmation
                    if content_len < 400 and elapsed < 1.5:
                        # Content looks incomplete - keep waiting
                        print(f"\r⚠  Content small ({content_len} chars), waiting longer...   ", end="", flush=True)
                        stable_count = stability_checks - 1  # Reset to need one more match
                    else:
                        # Content is stable and sufficient!
                        print("\r" + " " * 60 + "\r", end="", flush=True)  # Clear line
                        return (current_content, False)
            else:
                # Content changed, reset stability counter
                stable_count = 0
                previous_content = current_content

            # Visual feedback
            spinner = spinner_chars[attempt % len(spinner_chars)]
            stability_dots = "●" * stable_count + "○" * (stability_checks - stable_count)
            elapsed = initial_delay + sum([poll_interval * (backoff_factor ** i) for i in range(attempt)])
            print(f"\r{spinner} Waiting for output {stability_dots} ({elapsed:.1f}s)", end="", flush=True)

            # Adaptive wait with exponential backoff
            time.sleep(current_interval)
            current_interval = min(current_interval * backoff_factor, max_poll_interval)
            attempt += 1

        # Timeout - clear feedback line, return last content
        print("\r" + " " * 60 + "\r", end="", flush=True)
        return (current_content if current_content else "", True)

    def simple_snapshot_capture(self, terminal_uuid, lines=-1) -> str:
        """
        Simple direct snapshot of terminal content with no stability detection.

        This is ideal for:
        - TUI applications (htop, vim) that continuously update or wait for input
        - Watch mode captures (periodic snapshots)
        - Manual context captures

        Args:
            terminal_uuid: Terminal to capture
            lines: Number of lines to capture (-1 for auto-detect viewport)

        Returns:
            Terminal content as string
        """
        try:
            content = self.plugin_dbus.capture_terminal_content(terminal_uuid, lines)
            return content if content and not content.startswith('ERROR') else ""
        except Exception as e:
            self.console.print(f"[red]Snapshot capture error: {e}[/]")
            return ""

    def prompt_based_capture(self, terminal_uuid, max_wait=30) -> Tuple[bool, str]:
        """
        Capture terminal content using prompt detection instead of stability checks.

        Polls terminal and stops immediately when a shell prompt is detected.
        Falls back to timeout for long-running commands or TUI applications.

        This is ideal for:
        - Command-line tools that return to prompt quickly
        - Exec terminal command execution
        - Cases where prompt detection is more reliable than stability

        Args:
            terminal_uuid: Terminal to capture
            max_wait: Maximum wait time in seconds (default: 30)

        Returns:
            Tuple of (prompt_detected, content)
        """
        # Configuration
        initial_delay = 0.3
        poll_interval = 0.5
        max_attempts = int(max_wait / poll_interval)

        # Initial delay for command to start
        time.sleep(initial_delay)

        # Spinner animation
        spinner_chars = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]

        for attempt in range(max_attempts):
            try:
                content = self.plugin_dbus.capture_terminal_content(terminal_uuid, -1)

                # Check for prompt immediately
                if content and PromptDetector.detect_prompt(content):
                    # Clear spinner and return
                    print("\r" + " " * 60 + "\r", end="", flush=True)
                    return (True, content)

                # Visual feedback
                spinner = spinner_chars[attempt % len(spinner_chars)]
                elapsed = initial_delay + (attempt * poll_interval)
                print(f"\r{spinner} Waiting for prompt ({elapsed:.1f}s)", end="", flush=True)

                time.sleep(poll_interval)

            except Exception as e:
                self.console.print(f"[red]Prompt-based capture error: {e}[/]")
                return (False, "")

        # Timeout - return last content
        print("\r" + " " * 60 + "\r", end="", flush=True)
        return (False, content if content else "")

    def capture_context(self, include_exec_output=False) -> str:
        """
        Capture visible content from all terminals (like tmuxai).

        Excludes:
        - Chat terminal (where sidechat is running) - to avoid self-reference
        - Exec terminal (unless include_exec_output=True)

        Returns:
            Formatted context string with XML-wrapped terminal content
        """
        try:
            terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
            context_parts = []

            for term in terminals:
                # Skip chat terminal (self-awareness)
                if term['uuid'] == self.chat_terminal_uuid:
                    continue

                # Optionally skip exec terminal
                if not include_exec_output and term['uuid'] == self.exec_terminal_uuid:
                    continue

                # Capture visible content (auto-detect viewport size)
                content = self.plugin_dbus.capture_terminal_content(term['uuid'], -1)

                if content and not content.startswith('ERROR'):
                    # Format like tmux-fragments
                    context_parts.append(f'''<terminal uuid="{term['uuid']}" title="{term['title']}" cwd="{term['cwd']}">
{content}
</terminal>''')

            return "\n\n".join(context_parts)
        except Exception as e:
            self.console.print(f"[red]Error capturing context: {e}[/]")
            return ""

    def capture_context_intelligent(self, include_exec_output=False) -> str:
        """
        Capture context with intelligent stability detection.
        Uses adaptive polling to wait for terminal output to stabilize.

        Args:
            include_exec_output: If True, include exec terminal content

        Returns:
            Formatted context string with XML-wrapped terminal content
        """
        try:
            terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
            context_parts = []
            timeout_warnings = []

            for term in terminals:
                uuid = term.get('uuid')

                # Skip chat terminal (self-awareness)
                if uuid == self.chat_terminal_uuid:
                    continue

                # Optionally skip exec terminal
                if not include_exec_output and uuid == self.exec_terminal_uuid:
                    continue

                # Intelligent capture with stability detection
                content, timed_out = self.intelligent_capture_with_stability(uuid)

                if timed_out:
                    timeout_warnings.append(term.get('title', 'Unknown'))

                if content and not content.startswith('ERROR'):
                    # Format like tmux-fragments
                    context_parts.append(f'''<terminal uuid="{uuid}" title="{term['title']}" cwd="{term['cwd']}">
{content}
</terminal>''')

            # Show timeout warnings if any
            if timeout_warnings:
                warning_msg = ", ".join(timeout_warnings)
                self.console.print(f"[yellow]⚠ Capture timeout: {warning_msg}[/yellow]")

            return "\n\n".join(context_parts)
        except Exception as e:
            self.console.print(f"[red]Error capturing context: {e}[/]")
            return ""

    def estimate_tokens(self) -> int:
        """Estimate token count from conversation responses and system prompt"""
        total_chars = 0
        try:
            # Count system prompt
            total_chars += len(self.system_prompt)

            # Count all responses (includes prompts and AI responses)
            for response in self.conversation.responses:
                # Count the prompt
                if hasattr(response, 'prompt'):
                    prompt_obj = response.prompt
                    if hasattr(prompt_obj, 'prompt'):
                        total_chars += len(str(prompt_obj.prompt))
                    if hasattr(prompt_obj, 'system') and prompt_obj.system:
                        total_chars += len(str(prompt_obj.system))

                # Count the response text
                if hasattr(response, '_chunks'):
                    total_chars += sum(len(chunk) for chunk in response._chunks)
        except Exception as e:
            self.console.print(f"[yellow]Warning: Token estimation failed: {e}[/]")
        return total_chars // 4

    def check_and_squash_context(self):
        """Auto-squash when context reaches threshold (like tmuxai)"""
        current_tokens = self.estimate_tokens()

        if current_tokens >= self.max_context_size * self.context_squash_threshold:
            self.console.print("[yellow]Context approaching limit, auto-squashing...[/]")
            self.squash_context()

    def squash_context(self):
        """Compress earlier messages into summary (like tmuxai)"""
        if len(self.conversation.responses) <= 5:  # Keep at least 5 recent exchanges
            self.console.print("[yellow]Too few messages to squash[/]")
            return

        try:
            # Get responses to squash (all but last 3 - we'll re-execute those)
            responses_to_squash = self.conversation.responses[:-3]

            # Build summary from old responses
            summary_parts = []
            for i, response in enumerate(responses_to_squash, 1):
                # Extract prompt text
                prompt_text = ""
                if hasattr(response, 'prompt') and hasattr(response.prompt, '_prompt'):
                    prompt_text = response.prompt._prompt or ""

                # Extract response text
                response_text = ""
                if hasattr(response, '_chunks'):
                    response_text = "".join(response._chunks)

                if prompt_text:
                    summary_parts.append(f"{i}. User: {prompt_text[:200]}...")
                if response_text:
                    summary_parts.append(f"{i}. AI: {response_text[:200]}...")

            # Generate summary using a standalone prompt (not in conversation)
            summary_prompt = f"""Summarize this conversation history concisely, focusing on:
- Key technical issues discussed
- Commands executed and their results
- Important decisions or insights
- Relevant context for continuing the conversation

Previous messages:
{chr(10).join(summary_parts)}

Provide a brief but comprehensive summary."""

            summary_response = self.model.prompt(summary_prompt)
            summary = summary_response.text()

            # Create new conversation and update system prompt
            # Build enhanced system prompt from ORIGINAL, not current
            # This prevents infinite growth when squashing multiple times
            self.system_prompt = f"""{self.original_system_prompt}

[Previous conversation summary]
{summary}
[End of summary]"""

            # Create completely fresh conversation
            # We'll pass the new system prompt on the next user interaction
            self.conversation = llm.Conversation(model=self.model)

            new_tokens = self.estimate_tokens()
            self.console.print(f"[green]✓[/] Context squashed: ~{new_tokens} tokens")
            self.console.print(f"[cyan]Started fresh conversation with summary in system prompt[/]")

        except Exception as e:
            self.console.print(f"[red]Error squashing context: {e}[/]")

    def extract_commands(self, text: str) -> List[str]:
        """Extract bash commands from ```bash code blocks"""
        # Flexible pattern: allows whitespace after ```bash and optional newline before closing ```
        pattern = r'```bash\s*\n(.*?)\n?```'
        matches = re.findall(pattern, text, re.DOTALL)
        return [cmd.strip() for cmd in matches if cmd.strip()]

    def extract_keypresses(self, text: str) -> List[str]:
        """Extract keypresses from [▸] keypress blocks"""
        # Pattern: [▸] followed by keypress text (can be special key name or literal text)
        # Matches: [▸] :q  or  [▸] Enter  or  [▸] print("hello")
        pattern = r'\[▸\]\s*(.+?)(?=\n|$)'
        matches = re.findall(pattern, text, re.MULTILINE)
        return [kp.strip() for kp in matches if kp.strip()]

    def process_fragments(self, prompt: str):
        """
        Process !fragment commands in a prompt and return modified prompt plus resolved fragments.
        Based on llm.cli.process_fragments_in_chat

        Returns:
            (modified_prompt, fragments): Tuple of prompt text and list of Fragment objects
        """
        prompt_lines = []
        fragments = []

        for line in prompt.splitlines():
            if line.startswith("!fragment "):
                try:
                    fragment_strs = line.strip().removeprefix("!fragment ").split()
                    # Get llm database
                    db = llm.get_default_db()
                    # Resolve fragments
                    resolved = resolve_fragments(db, fragments=fragment_strs, allow_attachments=False)
                    fragments.extend(resolved)
                except FragmentNotFound as ex:
                    self.console.print(f"[red]Fragment error: {ex}[/]")
                    # Don't include the !fragment line but continue processing
                except Exception as ex:
                    self.console.print(f"[red]Error processing fragment: {ex}[/]")
            else:
                prompt_lines.append(line)

        return "\n".join(prompt_lines), fragments

    def wait_for_command_completion(self, timeout=30) -> Tuple[bool, str]:
        """
        Wait for command to complete using intelligent capture with stability detection.

        Returns:
            (completed, output): Boolean + captured output
        """
        try:
            # Use intelligent capture with stability detection
            # This handles timing, polling, and content validation automatically
            content, timed_out = self.intelligent_capture_with_stability(
                self.exec_terminal_uuid,
                max_wait=timeout
            )

            if timed_out:
                # Timeout occurred, but return whatever we captured
                return (False, content)

            # Content is stable - verify it looks reasonable
            if content and len(content) > 100:
                # Sanity check: verify prompt markers are present
                # This confirms command completed and shell is ready
                if PromptDetector.detect_prompt(content):
                    return (True, content)
                else:
                    # Content stable but no clear prompt - might be TUI or long output
                    # Still consider it successful
                    return (True, content)
            else:
                # Very short content - might be problematic
                return (False, content)

        except Exception as e:
            self.console.print(f"[yellow]Error during command wait: {e}[/]")
            return (False, "")

    def execute_command(self, command: str) -> bool:
        """
        Execute command in Exec terminal with user approval and intelligent completion detection.

        Returns:
            True if executed, False if skipped
        """
        # Smart detection: Check if this "command" is actually a special key
        # If so, automatically route to keypress handler instead
        if SPECIAL_KEY_PATTERN.match(command.strip()):
            self.console.print("[yellow]ℹ Detected special key in command block, routing to keypress handler[/]")
            executed = self.execute_keypress(command.strip())
            # Return tuple to match execute_command's return signature (bool, str)
            return (executed, "")

        self.console.print(Panel(
            Text(command, style="bold cyan"),
            title="[bold]Command to Execute[/]",
            border_style="cyan"
        ))

        # Ask for approval
        choice = Prompt.ask(
            "Execute in Exec terminal?",
            choices=["y", "n", "e"],  # yes, no, edit
            default="y"
        )

        if choice == "n":
            return False

        if choice == "e":
            # Allow editing
            edited = Prompt.ask("Edit command", default=command)
            command = edited

        # Verify exec terminal exists
        if not self._verify_exec_terminal():
            self.console.print("[yellow]Exec terminal not found[/]")
            if not self._recreate_exec_terminal():
                return False

        # Send to Exec terminal
        try:
            success = self.plugin_dbus.send_keys_to_terminal(
                self.exec_terminal_uuid,
                command,
                execute=True
            )

            if success:
                self.console.print("[green]✓[/] Command sent to Exec terminal")

                # Detect if this is a TUI application
                if is_tui_command(command):
                    # TUI detected - use screenshot capture
                    self.console.print("[cyan]TUI application detected - using screenshot capture[/]")
                    time.sleep(1.5)  # Give TUI time to fully render

                    try:
                        # Capture screenshot via plugin
                        screenshot_data = self.plugin_dbus.capture_terminal_screenshot(
                            self.exec_terminal_uuid
                        )

                        if screenshot_data.startswith('ERROR'):
                            # Escape brackets in error message for Rich markup
                            escaped_error = screenshot_data.replace('[', '[[').replace(']', ']]')
                            self.console.print(f"[red]{escaped_error}[/]")
                            return True, f"Screenshot capture failed: {screenshot_data}"

                        # Save screenshot to temporary file
                        import base64
                        image_bytes = base64.b64decode(screenshot_data)

                        temp_path = f"/tmp/sidechat_screenshot_{int(time.time())}.png"
                        with open(temp_path, 'wb') as f:
                            f.write(image_bytes)

                        self.console.print(f"[green]✓[/] TUI screenshot captured: {temp_path}")

                        # Return a message with the screenshot path
                        # The AI will be able to see this image via attachments
                        output = f"""TUI application screenshot saved to: {temp_path}

This is an interactive TUI application (like htop, vim, or less). The screenshot shows its current display state.

Screenshot size: {len(image_bytes)} bytes"""

                        return True, (output, temp_path)  # Return both text and image path

                    except Exception as e:
                        # Escape brackets in exception message for Rich markup
                        escaped_error = str(e).replace('[', '[[').replace(']', ']]')
                        self.console.print(f"[red]Screenshot capture error: {escaped_error}[/]")
                        return True, f"Screenshot capture failed: {e}"
                else:
                    # Regular command - use prompt-based capture
                    with self.console.status("[cyan]Waiting for command to complete..."):
                        prompt_detected, output = self.prompt_based_capture(
                            self.exec_terminal_uuid,
                            max_wait=30
                        )

                    if prompt_detected:
                        self.console.print("[green]✓[/] Command completed (prompt detected)")
                        return True, output
                    else:
                        self.console.print("[yellow]⚠[/] Timeout or long-running command")
                        return True, output
            else:
                self.console.print("[red]✗[/] Failed to send command")
                return False, ""
        except Exception as e:
            self.console.print(f"[red]Error executing command: {e}[/]")
            return False, ""

    def execute_keypress(self, keypress: str) -> bool:
        """
        Send keypress to Exec terminal with user approval.
        Does NOT automatically execute (no newline unless keypress is "Enter").

        Returns:
            True if sent, False if skipped
        """
        self.console.print(Panel(
            Text(f"[▸] {keypress}", style="bold magenta"),
            title="[bold]Keypress to Send[/]",
            border_style="magenta"
        ))

        # Ask for approval
        choice = Prompt.ask(
            "Send this key(s)?",
            choices=["y", "n", "e"],  # yes, no, edit
            default="y"
        )

        if choice == "n":
            return False

        if choice == "e":
            # Allow editing
            edited = Prompt.ask("Edit keypress", default=keypress)
            keypress = edited

        # Verify exec terminal exists
        if not self._verify_exec_terminal():
            self.console.print("[yellow]Exec terminal not found[/]")
            if not self._recreate_exec_terminal():
                return False

        # Send keypress to Exec terminal using new D-Bus method
        try:
            success = self.plugin_dbus.send_keypress_to_terminal(
                self.exec_terminal_uuid,
                keypress
            )

            if success:
                self.console.print(f"[green]✓[/] Keypress '{keypress}' sent to Exec terminal")
                return True
            else:
                self.console.print("[red]✗[/] Failed to send keypress")
                return False
        except Exception as e:
            self.console.print(f"[red]Error sending keypress: {e}[/]")
            return False

    def _start_watch_mode_thread(self):
        """Start watch mode in a background thread with its own event loop"""
        def watch_thread_target():
            self.event_loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.event_loop)
            try:
                self.event_loop.run_until_complete(self.watch_loop())
            except Exception as e:
                self.console.print(f"[red]Watch mode error: {e}[/]")
            finally:
                self.event_loop.close()

        self.watch_thread = threading.Thread(target=watch_thread_target, daemon=True)
        self.watch_thread.start()

    async def watch_loop(self):
        """Background monitoring of all terminals (like tmuxai watch mode)"""
        while self.watch_mode:
            try:
                # Capture all terminal content (including exec output for watch)
                context = self.capture_context(include_exec_output=True)

                if not context.strip():
                    await asyncio.sleep(self.watch_interval)
                    continue

                # Send to AI with watch goal
                prompt = f"""[Watch Mode] Goal: {self.watch_goal}

Current terminal state:
{context}

Based on the watch goal, analyze the terminal activity and provide suggestions ONLY if you observe something relevant to the goal. If everything looks normal, respond with "OK" only."""

                # Use conversation.prompt() for watch mode with thread safety
                # Note: We don't pass system prompt here as it should already be in conversation
                try:
                    # Keep lock held for entire response lifecycle to ensure thread safety
                    with self.watch_lock:
                        response = self.conversation.prompt(prompt)
                        # Consume response while holding lock to prevent concurrent modifications
                        response_text = response.text()

                    # Only show if AI has actionable feedback (not just "OK")
                    if response_text.strip() and response_text.strip().lower() != "ok":
                        self.console.print()
                        self.console.print(Panel(
                            Markdown(response_text),
                            title="[bold yellow]⚠ Watch Mode Alert[/]",
                            border_style="yellow"
                        ))
                        self.console.print()
                except Exception as response_error:
                    self.console.print(f"[yellow]Watch mode response error: {response_error}[/]")
                    # Continue watching despite error

            except Exception as e:
                self.console.print(f"[red]Watch mode error: {e}[/]")

            await asyncio.sleep(self.watch_interval)

    def handle_slash_command(self, command: str) -> bool:
        """
        Handle slash commands.

        Returns:
            True if should continue REPL, False to exit
        """
        parts = command.split(maxsplit=1)
        cmd = parts[0].lower()
        args = parts[1] if len(parts) > 1 else ""

        if cmd == "/help":
            self.console.print(Panel("""
[bold]Available Commands:[/]

/help              Show this help message
/clear             Clear conversation history
/reset             Clear conversation and reset terminal states
/refresh           Refresh terminal context (re-capture current state)
/model <name>      Switch model or list available models
/info              Show session information
/watch <goal>      Enable watch mode with goal
/watch off         Disable watch mode
/watch status      Show watch mode status
/squash            Manually compress conversation context
/quit or /exit     Exit sidechat

[bold]Usage:[/]
- Type messages to chat with AI
- AI provides commands in ```bash blocks
- Commands are sent to Exec terminal with approval
""", title="Sidechat Help", border_style="cyan"))
            return True

        elif cmd == "/clear":
            # Reset conversation (system prompt will be passed on next interaction)
            try:
                self.conversation = llm.Conversation(model=self.model)
                self.console.print("[green]✓[/] Conversation cleared")
            except Exception as e:
                self.console.print(f"[red]Error clearing conversation: {e}[/]")
            return True

        elif cmd == "/reset":
            # Clear conversation and reset terminal states (like tmuxai /reset)
            try:
                # Clear conversation
                self.conversation = llm.Conversation(model=self.model)

                # Reset system prompt to original
                self.system_prompt = self.original_system_prompt

                # Disable watch mode if active
                if self.watch_mode:
                    with self.watch_lock:
                        self.watch_mode = False
                        self.watch_goal = None
                        if self.event_loop:
                            try:
                                self.event_loop.call_soon_threadsafe(self.event_loop.stop)
                            except Exception:
                                pass

                # Clear plugin cache
                if self.plugin:
                    self.plugin_dbus.clear_cache()

                self.console.print("[green]✓[/] Conversation cleared and terminal states reset")
            except Exception as e:
                self.console.print(f"[red]Error resetting: {e}[/]")
            return True

        elif cmd == "/refresh":
            # Re-capture terminal content and show preview
            self.console.print("[cyan]Refreshing terminal context...[/]")

            # Clear plugin cache
            try:
                self.plugin_dbus.clear_cache()
            except Exception:
                pass

            # Simple snapshot capture (includes exec terminal)
            # Instant capture without stability detection
            context = self.capture_context(include_exec_output=True)

            if context:
                self.console.print(f"[green]✓[/] Captured {len(context)} characters of context")

                # Show per-terminal breakdown
                import re
                terminals = re.findall(r'<terminal uuid="([^"]+)" title="([^"]+)"', context)
                if terminals:
                    self.console.print("\n[bold]Terminals captured:[/]")
                    for uuid_match, title in terminals:
                        # Extract content for this terminal
                        term_pattern = rf'<terminal uuid="{re.escape(uuid_match)}"[^>]*>(.*?)</terminal>'
                        term_match = re.search(term_pattern, context, re.DOTALL)
                        if term_match:
                            term_content = term_match.group(1).strip()
                            lines = len([l for l in term_content.split('\n') if l.strip()])
                            chars = len(term_content)
                            self.console.print(f"  • [cyan]{title}[/]: {lines} lines, {chars} chars")

                # Show preview of first terminal
                self.console.print("\n[dim]First 300 chars of content:[/]")
                preview = context[:300].replace('\n', ' ')
                self.console.print(f"[dim]{preview}...[/]")
            else:
                self.console.print("[yellow]No context captured[/]")

            return True

        elif cmd == "/model":
            if not args:
                # List available models
                self.console.print("[bold]Available models:[/]")
                for model in llm.get_models():
                    current = " [green](current)[/]" if model.model_id == self.model_name else ""
                    self.console.print(f"  - {model.model_id}{current}")
            else:
                # Switch model
                try:
                    self.model = llm.get_model(args)
                    self.model_name = args
                    self.console.print(f"[green]✓[/] Switched to model: {args}")

                    # Update conversation model
                    self.conversation.model = self.model
                except Exception as e:
                    self.console.print(f"[red]Error switching model: {e}[/]")
            return True

        elif cmd == "/info":
            tokens = self.estimate_tokens()
            percentage = (tokens * 100 // self.max_context_size) if self.max_context_size > 0 else 0
            self.console.print(Panel(f"""
[bold]Session Information:[/]

Model: {self.model_name}
Context size: ~{tokens:,} tokens / {self.max_context_size:,} ({percentage}%)
Exchanges: {len(self.conversation.responses)}
Watch mode: {"enabled" if self.watch_mode else "disabled"}
{f"Watch goal: {self.watch_goal}" if self.watch_mode else ""}

Chat terminal: {self.chat_terminal_uuid[:16]}...
Exec terminal: {self.exec_terminal_uuid[:16]}...
""", title="Session Info", border_style="cyan"))
            return True

        elif cmd == "/watch":
            if not args or args.lower() == "off":
                # Disable watch mode
                if self.watch_mode:
                    with self.watch_lock:
                        self.watch_mode = False
                        if self.event_loop:
                            # Stop the loop gracefully
                            try:
                                self.event_loop.call_soon_threadsafe(self.event_loop.stop)
                            except Exception:
                                pass
                    self.console.print("[yellow]Watch mode disabled[/]")
                else:
                    self.console.print("[yellow]Watch mode is already off[/]")
            elif args.lower() == "status":
                # Show watch mode status
                if self.watch_mode:
                    self.console.print(f"[green]Watch mode: enabled[/]")
                    self.console.print(f"Goal: {self.watch_goal}")
                    self.console.print(f"Interval: {self.watch_interval}s")
                else:
                    self.console.print("[yellow]Watch mode: disabled[/]")
            else:
                # Enable watch mode with goal
                with self.watch_lock:
                    self.watch_mode = True
                    self.watch_goal = args
                    # Start watch thread immediately
                    self._start_watch_mode_thread()
                self.console.print(f"[green]✓[/] Watch mode enabled")
                self.console.print(f"Goal: {self.watch_goal}")
                self.console.print(f"Monitoring all terminals every {self.watch_interval}s...")
            return True

        elif cmd == "/squash":
            self.squash_context()
            return True

        elif cmd in ["/quit", "/exit"]:
            self._shutdown()  # Explicit cleanup before exit
            return False

        else:
            self.console.print(f"[red]Unknown command: {cmd}[/]")
            self.console.print("Type /help for available commands")
            return True

    def run(self):
        """Main REPL loop with health checks"""
        # Connect to Terminator
        self._connect_to_terminator()

        # Setup terminals
        self.setup_terminals()

        # Display welcome message
        self.console.print(Panel.fit(
            f"""[bold green]Terminator Sidechat Started[/]

Model: [cyan]{self.model_name}[/]

[bold]Commands:[/]
Type /help for slash commands
Type 'exit' or 'quit' to exit
Type !multi to enter multiple lines, then !end to finish
Type !fragment <name> [...] to insert fragments

[dim]AI will suggest [▸] keypresses for interactive apps[/]
""",
            title="llm-sidechat",
            border_style="green"
        ))

        # Main REPL loop with periodic health checks
        check_counter = 0

        # Multi-line input state
        in_multi = False
        accumulated_lines = []
        end_token = "!end"

        try:
            while True:
                # Periodic health check every 10 iterations
                check_counter += 1
                if check_counter >= 10:
                    # Check plugin availability
                    if not self._check_plugin_available():
                        self.console.print("[yellow]Plugin unavailable, attempting reconnect...[/]")
                        if not self._reconnect_plugin():
                            self.console.print("[red]Plugin reconnection failed. Please restart sidechat.[/]")
                            break

                    # Check D-Bus connection
                    if not self._check_dbus_connection():
                        self.console.print("[yellow]D-Bus disconnected, attempting reconnect...[/]")
                        if not self._reconnect_dbus():
                            self.console.print("[red]D-Bus reconnection failed. Please restart sidechat.[/]")
                            break

                    check_counter = 0

                # Get user input (change prompt based on mode)
                try:
                    if in_multi:
                        # Multi-line mode - simple dim prompt
                        # Use inline ANSI prompt to prevent backspace from deleting it
                        user_input = input("\033[2m...\033[0m ")
                    else:
                        # Regular mode - cyan > prompt
                        # Use inline ANSI prompt to prevent backspace from deleting it
                        user_input = input("\n\033[1;36m>\033[0m ").strip()
                except (KeyboardInterrupt, EOFError):
                    self.console.print("\n[yellow]Exiting...[/]")
                    break

                # Handle !multi command (start multi-line mode)
                if user_input.startswith("!multi"):
                    in_multi = True
                    bits = user_input.split()
                    if len(bits) > 1:
                        end_token = f"!end {' '.join(bits[1:])}"
                    else:
                        end_token = "!end"
                    self.console.print(f"[dim]Multi-line mode. Type '{end_token}' to finish[/]")
                    continue

                # Handle multi-line input accumulation
                if in_multi:
                    if user_input == end_token:
                        # Join accumulated lines and process
                        user_input = "\n".join(accumulated_lines)
                        accumulated_lines = []
                        in_multi = False
                    else:
                        # Accumulate this line
                        accumulated_lines.append(user_input)
                        continue

                if not user_input:
                    continue

                # Handle exit/quit commands (like llm chat mode)
                if user_input in ("exit", "quit"):
                    self.console.print("\n[yellow]Exiting...[/]")
                    self._shutdown()
                    break

                # Handle slash commands
                if user_input.startswith('/'):
                    should_continue = self.handle_slash_command(user_input)
                    if not should_continue:
                        break
                    continue

                # Clear plugin cache to ensure fresh capture
                try:
                    self.plugin_dbus.clear_cache()
                except Exception:
                    pass  # Ignore if clear_cache not available

                # Simple snapshot capture (no stability detection)
                # Works better for TUI applications and provides instant feedback
                context = self.capture_context(include_exec_output=False)

                # Process fragments if present
                processed_input, fragments = self.process_fragments(user_input)

                # Build prompt with context
                if context:
                    full_prompt = f"""{processed_input}

[Current terminal context]
{context}
"""
                else:
                    full_prompt = processed_input

                # Check if we need to squash context
                self.check_and_squash_context()

                # Send to AI with streaming
                # Pass system prompt on first interaction or when conversation is empty
                response_text = ""
                stream_success = False

                try:
                    self.console.print("\n[bold green]ai[/]")

                    # Thread-safe conversation access
                    with self.watch_lock:
                        # Pass system prompt if this is the first interaction
                        # Also pass fragments if any were specified
                        if len(self.conversation.responses) == 0:
                            response = self.conversation.prompt(full_prompt, system=self.system_prompt, attachments=fragments)
                        else:
                            response = self.conversation.prompt(full_prompt, attachments=fragments)

                        # Stream the response with Rich Live display for proper markdown formatting
                        # Using Live display to update markdown rendering as chunks arrive
                        with Live(Markdown(""), console=self.console, refresh_per_second=10) as live:
                            for chunk in response:
                                response_text += chunk
                                live.update(Markdown(response_text))

                    # No need for extra newline - Rich Live handles formatting
                    stream_success = True

                except Exception as e:
                    print()  # Ensure newline even on error
                    self.console.print(f"\n[red]Streaming error: {e}[/]")
                    self.console.print("[yellow]Response may be incomplete. Please try again.[/]")
                    # Don't process commands or update conversation on stream failure
                    continue

                # Only process commands and keypresses if streaming succeeded
                if stream_success:
                    try:
                        # Extract and execute commands
                        commands = self.extract_commands(response_text)
                        keypresses = self.extract_keypresses(response_text)

                        if commands:
                            self.console.print(f"\n[cyan]Found {len(commands)} command(s)[/]")

                            for i, cmd in enumerate(commands, 1):
                                if len(commands) > 1:
                                    self.console.print(f"\n[bold]Command {i}/{len(commands)}[/]")

                                executed, exec_content = self.execute_command(cmd)

                                if executed:
                                    # Handle TUI screenshot vs regular text output
                                    screenshot_path = None
                                    if isinstance(exec_content, tuple):
                                        # TUI command returned (text, image_path)
                                        exec_text, screenshot_path = exec_content
                                    else:
                                        # Regular command returned text only
                                        exec_text = exec_content

                                    # DEBUG: Show what was captured
                                    self.console.print(f"\n[yellow]═══ DEBUG: Captured Content ═══[/]")
                                    self.console.print(f"[yellow]UUID: {self.exec_terminal_uuid}[/]")
                                    if screenshot_path:
                                        self.console.print(f"[yellow]Type: Screenshot (TUI)[/]")
                                        self.console.print(f"[yellow]Screenshot path: {screenshot_path}[/]")
                                        self.console.print(f"[yellow]Description length: {len(exec_text)} chars[/]")
                                    else:
                                        self.console.print(f"[yellow]Type: Text output[/]")
                                        self.console.print(f"[yellow]Length: {len(exec_text)} chars[/]")
                                        self.console.print(f"[yellow]Is ERROR: {exec_text.startswith('ERROR') if exec_text else 'N/A (empty)'}[/]")
                                        self.console.print(f"[yellow]First 300 chars:[/]")
                                        self.console.print(f"[cyan]{exec_text[:300] if exec_text else '(empty)'}[/]")
                                    self.console.print(f"[yellow]═══════════════════════════════[/]\n")

                                    # Build prompt with command execution context
                                    if screenshot_path:
                                        exec_context_prompt = f"""Command executed in Exec terminal:
```bash
{cmd}
```

{exec_text}

Please analyze the screenshot and provide feedback on what you observe."""
                                    else:
                                        exec_context_prompt = f"""Command executed in Exec terminal:
```bash
{cmd}
```

Output:
```
{exec_text}
```

Please analyze the output and provide feedback if needed."""

                                    # Send the exec output to the conversation so AI can see results
                                    # Thread-safe conversation access
                                    with self.watch_lock:
                                        # Prepare attachments (screenshot if available)
                                        exec_attachments = []
                                        if screenshot_path:
                                            try:
                                                # Use llm's attachment system to attach the image
                                                exec_attachments.append(llm.Attachment(path=screenshot_path))
                                                self.console.print(f"[cyan]Sending screenshot to AI via vision model...[/]")
                                            except Exception as e:
                                                self.console.print(f"[yellow]Warning: Could not attach screenshot: {e}[/]")

                                        followup_response = self.conversation.prompt(
                                            exec_context_prompt,
                                            attachments=exec_attachments if exec_attachments else None
                                        )
                                        # Consume response while holding lock
                                        followup_text = followup_response.text()

                                    # DEBUG: Show AI response handling
                                    self.console.print(f"\n[yellow]═══ DEBUG: AI Response ═══[/]")
                                    self.console.print(f"[yellow]Length: {len(followup_text)} chars[/]")
                                    self.console.print(f"[yellow]Stripped lowercase: '{followup_text.strip().lower()[:100]}'[/]")
                                    self.console.print(f"[yellow]Will be filtered (hidden): {followup_text.strip().lower() in ['ok', 'okay', 'done']}[/]")
                                    self.console.print(f"[yellow]═══════════════════════════[/]\n")

                                    # Display the AI's analysis
                                    if followup_text.strip() and followup_text.strip().lower() not in ["ok", "okay", "done"]:
                                        self.console.print("\n[bold green]ai[/]")
                                        self.console.print(Markdown(followup_text))

                        # Extract and execute keypresses
                        if keypresses:
                            self.console.print(f"\n[magenta]Found {len(keypresses)} keypress(es)[/]")

                            for i, kp in enumerate(keypresses, 1):
                                if len(keypresses) > 1:
                                    self.console.print(f"\n[bold]Keypress {i}/{len(keypresses)}[/]")

                                self.execute_keypress(kp)

                    except Exception as e:
                        self.console.print(f"\n[red]Command/keypress execution error: {e}[/]")

        finally:
            # Unified cleanup - handles all resources
            self._shutdown()


def main():
    """Entry point"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Terminator AI Sidechat - Terminal assistant for pair programming"
    )
    parser.add_argument(
        'model',
        nargs='?',
        help='LLM model to use (default: azure/gpt-4.1-mini)'
    )
    args = parser.parse_args()

    session = TerminatorSidechatSession(model_name=args.model)
    session.run()


if __name__ == "__main__":
    main()
