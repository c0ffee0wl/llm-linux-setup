#!/bin/sh
''''exec "$HOME/.local/share/uv/tools/llm/bin/python3" "$0" "$@" # '''
"""
llm-sidechat - Terminal AI Assistant for Terminator

A Terminator-integrated AI assistant that provides:
- Automatic Exec terminal creation
- Terminal content capture and analysis
- Command execution with approval
- Watch Mode for proactive monitoring
- Context squashing to manage token limits
- Streaming responses with markdown rendering
- Robust error handling and recovery

Inspired by TmuxAI but designed for Terminator terminal emulator.

Author: c0ffee0wl
License: GPL v2 only
"""

import sys
import json
import base64
import uuid

import llm
from llm import Tool, ToolResult, Attachment
from llm.cli import load_template, resolve_fragments, FragmentNotFound

# Add system site-packages to path for dbus and other system-only packages
# (Must be AFTER llm imports to avoid typing_extensions conflicts)
sys.path.insert(0, '/usr/lib/python3/dist-packages')
# Add user site-packages for llm_tools module (uv's isolated env doesn't include it)
import site
sys.path.insert(0, site.getusersitepackages())
import os
import re
import readline  # Required for \001/\002 prompt markers to work with input()
import time
import hashlib
import tempfile
import asyncio
import threading
import dbus
import fcntl
import signal
import atexit
from pathlib import Path
from rich.console import Console
from rich.live import Live
from rich.markdown import Markdown
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.text import Text
from typing import List, Optional, Tuple, Dict

# Import shared prompt detection module
try:
    from llm_tools.prompt_detection import PromptDetector
except ImportError:
    # Fallback for development - import from context directory
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'context'))
    from prompt_detection import PromptDetector


# Common TUI applications that use screenshot capture instead of text
# All lowercase for case-insensitive matching
TUI_COMMANDS = {
    # System monitors
    'htop', 'top', 'btop', 'gtop', 'glances', 'atop', 'nmon',
    'iotop', 'iftop', 'nethogs', 'bmon', 'vnstat', 'procs',
    # Editors
    'vim', 'vi', 'nvim', 'nano', 'emacs', 'helix', 'micro',
    'joe', 'pico', 'jed', 'ne', 'mg', 'kakoune', 'kak',
    # Pagers
    'less', 'more', 'most', 'bat',
    # File managers
    'mc', 'ranger', 'nnn', 'lf', 'vifm', 'fff', 'broot',
    'ncdu', 'duf', 'dust',
    # Terminal multiplexers
    'tmux', 'screen', 'byobu', 'zellij',
    # Git TUIs
    'tig', 'lazygit', 'gitui',
    # Container/K8s TUIs
    'k9s', 'lazydocker', 'dive', 'ctop',
    # Fuzzy finders (when run standalone)
    'fzf', 'sk', 'peco',
    # Periodic execution
    'watch',
    # Audio
    'alsamixer', 'pulsemixer',
    # Email/IRC
    'mutt', 'neomutt', 'aerc',
    'weechat', 'irssi',
    # Music players
    'cmus', 'ncmpcpp', 'moc', 'mocp',
    # Web browsers
    'lynx', 'w3m', 'links', 'elinks',
    # Task management
    'taskwarrior-tui', 'taskell',
    # Calendar
    'calcurse', 'khal',
}

# Patterns for AI-requested captures (XML tags)
# <CAPTURE/> or <CAPTURE>all</CAPTURE> - request screenshot
SCREENSHOT_REQUEST_PATTERN = re.compile(r'<CAPTURE(?:\s*/\s*>|>(all)?</CAPTURE>)', re.IGNORECASE)
# <REFRESH/> - request context refresh
CONTEXT_REFRESH_PATTERN = re.compile(r'<REFRESH\s*/?\s*>', re.IGNORECASE)
# <EXECUTE>...</EXECUTE> - command execution
EXECUTE_PATTERN = re.compile(
    r'<\s*EXECUTE\s*>(.*?)<\s*/\s*EXECUTE\s*>',
    re.DOTALL | re.IGNORECASE
)
# <PRESSKEY>...</PRESSKEY> - keypress
PRESSKEY_PATTERN = re.compile(
    r'<\s*PRESSKEY\s*>(.*?)<\s*/\s*PRESSKEY\s*>',
    re.DOTALL | re.IGNORECASE
)


# =============================================================================
# Tool Definitions for Structured Output
# =============================================================================
# These tools provide structured interfaces for terminal operations.
# They are "stub" tools - they return structured JSON to indicate intent,
# but the actual execution is handled by the sidechat main loop.
# This approach provides schema validation at the model level.

def execute_in_terminal(command: str) -> str:
    """
    Execute a shell command in the Exec terminal.

    Use this tool to run commands in the designated execution terminal.
    The command will be sent to the terminal and its output captured.

    Always explain your reasoning before using this tool - describe what
    you're about to do and why.

    Args:
        command: The shell command to execute (e.g., "ls -la", "git status")

    Returns:
        JSON indicating the command has been queued for execution.
        Actual execution is handled by sidechat with user approval.
    """
    return json.dumps({
        "action": "execute",
        "command": command,
        "status": "queued"
    })


def send_keypress(keypress: str) -> str:
    """
    Send a keypress or key sequence to the Exec terminal.

    Use this for interactive applications (TUIs) that need keyboard input,
    such as vim, less, htop, or any application expecting keypresses.

    Supported special keys:
    - Enter, Escape, Tab, Space, Backspace, Delete
    - Ctrl+<key> (e.g., "Ctrl+C", "Ctrl+D", "Ctrl+Z")
    - Alt+<key> (e.g., "Alt+F", "Alt+B")
    - Arrow keys: Up, Down, Left, Right
    - Function keys: F1-F12
    - Page keys: PageUp, PageDown, Home, End

    For regular text input, just use the characters directly (e.g., ":wq" for vim).

    Always explain your reasoning before using this tool.

    Args:
        keypress: The key or key sequence to send (e.g., "Enter", "Ctrl+C", ":wq", "q")

    Returns:
        JSON indicating the keypress has been queued.
        Actual execution is handled by sidechat with user approval.
    """
    return json.dumps({
        "action": "keypress",
        "key": keypress,
        "status": "queued"
    })


def capture_terminal(scope: str = "exec") -> str:
    """
    Capture terminal content or screenshot.

    Use this to see the current state of the terminal(s). For TUI applications
    (vim, htop, etc.), this captures a screenshot. For regular command output,
    it captures the text content.

    Args:
        scope: Which terminals to capture:
               - "exec": Only the Exec terminal (default)
               - "all": All visible terminals

    Returns:
        JSON indicating capture has been queued.
        The captured content will be provided in the next context.
    """
    valid_scopes = ["exec", "all"]
    if scope not in valid_scopes:
        scope = "exec"

    return json.dumps({
        "action": "capture",
        "scope": scope,
        "status": "queued"
    })


def refresh_context() -> str:
    """
    Refresh the terminal context before continuing.

    Use this when you need updated terminal content before deciding
    what to do next. This is useful when:
    - You're waiting for a long-running command to complete
    - You want to see the current state without executing anything
    - The terminal content may have changed since your last observation

    Returns:
        JSON indicating refresh has been queued.
        Updated context will be provided in the next message.
    """
    return json.dumps({
        "action": "refresh",
        "status": "queued"
    })


# Create Tool objects from the functions
SIDECHAT_TOOLS = [
    Tool.function(execute_in_terminal),
    Tool.function(send_keypress),
    Tool.function(capture_terminal),
    Tool.function(refresh_context),
]


def is_tui_command(command: str) -> bool:
    """
    Detect if a command will launch a TUI application.

    Handles piped commands by checking the rightmost command,
    since that's what actually displays in the terminal.

    Args:
        command: Full command string (e.g., "htop -d 5" or "git log | less")

    Returns:
        True if command is a known TUI application
    """
    if not command.strip():
        return False

    # For piped commands, check the rightmost command (that's what displays)
    # e.g., "cat file | less" -> check "less"
    # e.g., "git log | head" -> check "head" (not TUI)
    if '|' in command:
        parts = command.split('|')
        command = parts[-1].strip()

    # Extract the base command (first word)
    base_cmd = command.split()[0] if command.split() else ""

    # Remove path if present (e.g., /usr/bin/htop -> htop)
    # Use lowercase for case-insensitive matching
    base_cmd = os.path.basename(base_cmd).lower()

    return base_cmd in TUI_COMMANDS


class TerminatorSidechatSession:
    """Main sidechat session manager for Terminator"""

    def __init__(self, model_name: Optional[str] = None, debug: bool = False, capture_timeout: float = 3.0):
        self.console = Console()

        # Debug mode flag
        self.debug = debug

        # Initialize shutdown state and lock file handle
        self._shutdown_initiated = False
        self.lock_file = None

        # Acquire instance lock FIRST (before any other initialization)
        self._acquire_instance_lock()

        # Register shutdown handlers EARLY (before creating resources)
        self._register_shutdown_handlers()

        self.model_name = model_name or self._get_default_model()

        try:
            self.model = llm.get_model(self.model_name)
        except Exception as e:
            self.console.print(f"[red]Error loading model '{self.model_name}': {e}[/]")
            self.console.print("[yellow]Available models:[/]")
            for model in llm.get_models():
                self.console.print(f"  - {model.model_id}")
            sys.exit(1)

        self.conversation = llm.Conversation(model=self.model)

        # Store system prompt separately for reuse
        try:
            template = load_template("terminator-sidechat")
            # Use system if available, otherwise use prompt
            self.system_prompt = template.system or template.prompt
            if not self.system_prompt:
                raise ValueError("Template has no system or prompt field")
        except Exception as e:
            self.console.print(f"[yellow]⚠ Could not load terminator-sidechat template: {e}[/]")
            self.console.print("[yellow]Using basic system prompt. Install template with: ./install-llm-tools.sh[/]")
            self.system_prompt = "You are an AI terminal assistant. Provide commands in <EXECUTE>command</EXECUTE> XML tags."

        # Store original system prompt for context squashing
        # This prevents infinite growth when squashing multiple times
        self.original_system_prompt = self.system_prompt

        # Terminal tracking
        self.chat_terminal_uuid = None
        self.exec_terminal_uuid = None

        # Context management (like tmuxai)
        self.max_context_size = 100000  # tokens
        self.context_squash_threshold = 0.8  # 80%

        # Token count cache (avoids O(n) recalculation on every input)
        self._cached_token_count = 0
        self._cached_response_count = 0

        # Watch mode (thread-safe)
        self.watch_mode = False
        self.watch_goal = None
        self.watch_thread = None
        self.watch_task = None  # Asyncio task for graceful cancellation
        self.watch_interval = 5  # seconds
        self.watch_lock = threading.Lock()
        self.event_loop = None
        # Watch mode intelligent change detection
        self.previous_watch_context_hash = None  # SHA256 hash for deduplication
        self.previous_watch_iteration_count = 0   # Track iterations for prompt

        # Intelligent capture timing configuration
        self.capture_config = {
            'initial_delay': 0.3,        # Initial wait before first capture (seconds)
            'poll_interval': 0.2,        # Starting poll interval (seconds)
            'max_poll_interval': 1.0,    # Maximum poll interval (seconds)
            'backoff_factor': 1.3,       # Exponential backoff multiplier
            'stability_checks': 3,       # Consecutive matches needed for stability
            'max_wait': capture_timeout, # Total timeout (seconds) - configurable via CLI
            'min_wait_before_stability': 0.5,  # Minimum wait before allowing stability detection
        }

        # D-Bus connections
        self.dbus_service = None

        # Track screenshot files for cleanup
        self.screenshot_files = []

    def _acquire_instance_lock(self):
        """
        Ensure only one sidechat instance per user session.
        Uses file locking with automatic cleanup on process exit.
        Detects and cleans up stale locks from crashed processes.
        """
        # Use runtime directory for lock file (XDG_RUNTIME_DIR or /tmp)
        runtime_dir = os.environ.get('XDG_RUNTIME_DIR', '/tmp')
        lock_path = Path(runtime_dir) / 'llm-sidechat.lock'

        # Check for stale lock before attempting to acquire
        if lock_path.exists():
            try:
                with open(lock_path, 'r') as f:
                    old_pid_str = f.read().strip()
                    if old_pid_str:
                        old_pid = int(old_pid_str)
                        # Check if process is still running
                        try:
                            os.kill(old_pid, 0)  # Signal 0 checks if process exists
                            # Process exists, lock is valid - will fail below
                        except OSError:
                            # Process doesn't exist - stale lock, clean up silently
                            lock_path.unlink()
            except (ValueError, IOError):
                # Can't read PID or file issues - try to proceed anyway
                pass

        try:
            # Open lock file (create if doesn't exist)
            self.lock_file = open(lock_path, 'w')

            # Try to acquire exclusive lock (non-blocking)
            fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

            # Write PID for debugging (optional but helpful)
            self.lock_file.write(f"{os.getpid()}\n")
            self.lock_file.flush()

        except BlockingIOError:
            # Lock is held by another instance
            self.console.print("[red]Error: Another sidechat instance is already running[/]")
            self.console.print("[yellow]Only one sidechat session can run at a time.[/]")
            self.console.print(f"[yellow]Lock file: {lock_path}[/]")

            # Try to read PID from lock file
            try:
                with open(lock_path, 'r') as f:
                    pid = f.read().strip()
                    if pid:
                        self.console.print(f"[yellow]Existing instance PID: {pid}[/]")
            except Exception:
                pass

            sys.exit(1)

        except Exception as e:
            self.console.print(f"[red]Error acquiring lock: {e}[/]")
            # Clean up file handle if it was opened before the exception
            if self.lock_file:
                try:
                    self.lock_file.close()
                except Exception:
                    pass
            sys.exit(1)

    def _release_instance_lock(self):
        """Release the instance lock (automatic on process exit, but explicit is better)"""
        if self.lock_file:
            try:
                fcntl.flock(self.lock_file.fileno(), fcntl.LOCK_UN)
                self.lock_file.close()
                self.lock_file = None
            except Exception:
                pass  # Lock will be released by kernel anyway

    def _register_shutdown_handlers(self):
        """Register signal handlers and atexit hook for cleanup"""
        # Register atexit fallback (runs on normal exit)
        atexit.register(self._shutdown)

        # Register signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, self._signal_handler)  # kill command
        signal.signal(signal.SIGHUP, self._signal_handler)   # Terminal closed

    def _signal_handler(self, signum, frame):
        """Handle termination signals"""
        signal_names = {
            signal.SIGINT: "SIGINT (Ctrl+C)",
            signal.SIGTERM: "SIGTERM",
            signal.SIGHUP: "SIGHUP (terminal closed)"
        }
        signal_name = signal_names.get(signum, f"signal {signum}")

        self.console.print(f"\n[yellow]Received {signal_name}, shutting down...[/]")
        self._shutdown()
        sys.exit(0)  # Exit cleanly

    def _shutdown(self):
        """
        Unified shutdown method - called by signal handlers, atexit, or manual exit.
        Idempotent - safe to call multiple times.
        """
        # Prevent double-cleanup
        if self._shutdown_initiated:
            return
        self._shutdown_initiated = True

        try:
            # STEP 1: Stop watch mode (most critical - prevents new threads)
            if hasattr(self, 'watch_mode') and self.watch_mode:
                try:
                    with self.watch_lock:
                        self.watch_mode = False
                        if self.watch_task and not self.watch_task.done():
                            try:
                                self.event_loop.call_soon_threadsafe(self.watch_task.cancel)
                            except RuntimeError:
                                pass  # Loop already closed

                    # Wait for watch thread to finish (with timeout)
                    if self.watch_thread and self.watch_thread.is_alive():
                        self.watch_thread.join(timeout=2.0)
                except Exception:
                    # Don't let watch mode cleanup prevent other cleanup
                    pass

            # STEP 2: Clean up screenshot files
            if hasattr(self, 'screenshot_files') and self.screenshot_files:
                for screenshot_path in self.screenshot_files:
                    try:
                        if os.path.exists(screenshot_path):
                            os.unlink(screenshot_path)
                    except (IOError, OSError):
                        pass  # Ignore cleanup errors
                self.screenshot_files.clear()

            # STEP 3: Clear plugin cache (if available)
            if hasattr(self, 'plugin_dbus'):
                try:
                    self.plugin_dbus.clear_cache()
                except Exception:
                    pass

            # STEP 4: Close D-Bus connections (graceful disconnect)
            # D-Bus connections don't need explicit cleanup in Python - garbage collected
            # But we can dereference them to signal intent
            if hasattr(self, 'dbus_service'):
                self.dbus_service = None
            if hasattr(self, 'plugin_dbus'):
                self.plugin_dbus = None

            # STEP 5: Release instance lock (most important)
            self._release_instance_lock()

            # STEP 6: Save conversation state (if needed)
            # llm library auto-saves, but we can explicitly flush here
            if hasattr(self, 'conversation'):
                try:
                    # Force any pending writes to complete
                    # llm Conversation doesn't have explicit save(), it auto-saves
                    pass
                except Exception:
                    pass

        except Exception as e:
            # Ensure we log errors but don't prevent shutdown
            try:
                self.console.print(f"[yellow]Warning during shutdown: {e}[/]")
            except Exception:
                # If console fails, write to stderr
                print(f"Warning during shutdown: {e}", file=sys.stderr)

    def _get_default_model(self) -> str:
        """Get default model from llm configuration"""
        try:
            return llm.get_default_model()
        except Exception:
            return "azure/gpt-4.1-mini"

    def _debug(self, msg: str):
        """Print debug message if debug mode is enabled"""
        if self.debug:
            self.console.print(f"[dim]DEBUG: {msg}[/dim]")

    def _normalize_uuid(self, uuid_value) -> Optional[str]:
        """Normalize UUID to Python string (ensures dbus.String -> str conversion)"""
        if uuid_value is None or uuid_value == '':
            return None
        # Explicitly convert to Python str (handles dbus.String)
        return str(uuid_value)

    def _reconnect_dbus(self) -> bool:
        """Attempt to reconnect to Terminator D-Bus with timeout"""
        # Use SIGALRM for timeout (safe at startup, before asyncio event loop)
        def timeout_handler(signum, frame):
            raise TimeoutError("D-Bus connection timed out")

        old_handler = signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(10)  # 10 second timeout

        try:
            bus = dbus.SessionBus()

            # Discover actual Terminator service name (includes UUID suffix)
            # Check for multiple instances
            terminator_services = [
                name for name in bus.list_names()
                if name.startswith('net.tenshu.Terminator2') and not name.endswith('.Sidechat')
            ]

            if len(terminator_services) > 1:
                self.console.print(f"[yellow]Multiple Terminator instances detected ({len(terminator_services)})[/]")
                self.console.print(f"[yellow]Using first found: {terminator_services[0]}[/]")

            service_name = terminator_services[0] if terminator_services else None

            if not service_name:
                service_name = 'net.tenshu.Terminator2'  # Fallback for older versions

            self._debug(f"Connected to Terminator D-Bus: {service_name}")
            self.dbus_service = bus.get_object(service_name, '/net/tenshu/Terminator2')
            return True
        except TimeoutError:
            self.console.print("[red]D-Bus connection timed out (10s)[/]")
            self.console.print("[yellow]Terminator may not be running or D-Bus is unresponsive[/]")
            return False
        except dbus.exceptions.DBusException as e:
            self.console.print(f"[red]D-Bus reconnection failed: {e}[/]")
            return False
        except Exception as e:
            self.console.print(f"[red]D-Bus reconnection error ({type(e).__name__}): {e}[/]")
            return False
        finally:
            signal.alarm(0)  # Cancel alarm
            signal.signal(signal.SIGALRM, old_handler)  # Restore handler

    def _check_dbus_connection(self) -> bool:
        """Verify D-Bus is still connected"""
        try:
            # Try a simple D-Bus operation
            self.dbus_service.get_terminals()
            return True
        except Exception:
            return False

    def _connect_to_terminator(self):
        """Connect to Terminator and plugin via D-Bus"""
        # Connect to Terminator's main D-Bus service for terminal management
        if not self._reconnect_dbus():
            self.console.print("[red]Error: Could not connect to Terminator D-Bus service[/]")
            self.console.print("Ensure Terminator is running with D-Bus enabled")
            sys.exit(1)

        # Connect to plugin's D-Bus service for terminal content/commands
        if not self._connect_to_plugin_dbus():
            self.console.print("[red]Error: Plugin D-Bus service not available[/]")
            self.console.print("Ensure TerminatorSidechat plugin is:")
            self.console.print("  1. Installed in ~/.config/terminator/plugins/")
            self.console.print("  2. Enabled in Terminator Preferences > Plugins")
            self.console.print("  3. Terminator has been restarted after enabling")
            sys.exit(1)

    def _connect_to_plugin_dbus(self) -> bool:
        """Connect to plugin's D-Bus service"""
        try:
            bus = dbus.SessionBus()
            self.plugin_dbus = bus.get_object(
                'net.tenshu.Terminator2.Sidechat',
                '/net/tenshu/Terminator2/Sidechat'
            )

            # Log plugin version for diagnostics (debug only)
            try:
                version = self.plugin_dbus.get_plugin_version()
                self._debug(f"Plugin version: {version}")
            except Exception:
                pass  # Ignore version check failures

            return True
        except Exception as e:
            self.console.print(f"[yellow]Plugin D-Bus connection failed: {e}[/]")
            return False

    def _check_plugin_available(self) -> bool:
        """Verify plugin D-Bus service is available"""
        try:
            # Try a simple D-Bus call to check if service is alive
            self.plugin_dbus.get_focused_terminal_uuid()
            return True
        except Exception:
            return False

    def _reconnect_plugin(self) -> bool:
        """Attempt to reconnect to plugin D-Bus service"""
        return self._connect_to_plugin_dbus()

    def setup_terminals(self):
        """Auto-create Exec terminal with retry logic"""
        self.console.print("[cyan]Setting up terminals...[/]")

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # Check D-Bus connection
                if not self._check_dbus_connection():
                    if not self._reconnect_dbus():
                        raise Exception("D-Bus reconnection failed")

                # Get current (Chat) terminal UUID
                focused_terminal = self.dbus_service.get_focused_terminal()
                if not focused_terminal:
                    raise Exception("No terminal is currently focused. Please focus a terminal and try again.")
                self.chat_terminal_uuid = self._normalize_uuid(focused_terminal)

                # Check for existing Exec pane or offer to reuse single other pane
                try:
                    terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
                    chat_uuid_normalized = self._normalize_uuid(self.chat_terminal_uuid)

                    # Filter out chat terminal
                    other_terminals = [t for t in terminals if self._normalize_uuid(t['uuid']) != chat_uuid_normalized]

                    # First: Look for existing Sidechat Exec pane by title
                    exec_candidates = [t for t in other_terminals if t.get('title', '').startswith('Sidechat: Exec')]
                    if exec_candidates:
                        # Reuse existing exec pane silently
                        self.exec_terminal_uuid = self._normalize_uuid(exec_candidates[0]['uuid'])
                        self.console.print("[green]✓[/] Terminals ready")
                        return  # Success - reusing existing exec terminal

                    # Second: If exactly one other pane, offer to use it
                    if len(other_terminals) == 1:
                        existing_pane = other_terminals[0]
                        pane_title = existing_pane.get('title', 'Untitled')
                        use_existing = Confirm.ask(f"Use '{pane_title}' as Exec pane?", default=True)

                        if use_existing:
                            self.exec_terminal_uuid = self._normalize_uuid(existing_pane['uuid'])
                            self.console.print("[green]✓[/] Terminals ready")
                            return  # Success - using existing terminal
                except dbus.exceptions.DBusException as e:
                    # D-Bus specific errors (method not found, connection issues, etc.)
                    error_msg = str(e)
                    if 'Unknown method' in error_msg or 'does not exist' in error_msg:
                        self.console.print("[red]ERROR: Plugin method 'get_terminals_in_same_window' not found![/]")
                        self.console.print("[red]Please restart Terminator to load the updated plugin.[/red]")
                    else:
                        self.console.print(f"[red]D-Bus error enumerating terminals: {e}[/]")
                    self.console.print("[yellow]Creating new Exec terminal as fallback...[/]")
                except Exception as e:
                    # Other unexpected errors
                    self.console.print(f"[red]Unexpected error ({type(e).__name__}): {e}[/]")
                    self.console.print("[yellow]Creating new Exec terminal as fallback...[/]")

                # Split vertically to create Exec terminal (to the right)
                exec_uuid = self.dbus_service.vsplit(
                    self.chat_terminal_uuid,
                    dbus.Dictionary({
                        'title': 'Sidechat: Exec'
                    }, signature='ss')
                )
                if str(exec_uuid).startswith('ERROR'):
                    raise Exception(f"Failed to split terminal: {exec_uuid}")
                self.exec_terminal_uuid = self._normalize_uuid(exec_uuid)

                self.console.print("[green]✓[/] Terminals ready")
                return  # Success

            except Exception as e:
                if attempt < max_retries - 1:
                    self.console.print(f"[yellow]Retry {attempt+1}/{max_retries}: {e}[/]")
                    time.sleep(1)
                else:
                    self.console.print(f"[red]Failed to setup terminals after {max_retries} attempts: {e}[/]")
                    sys.exit(1)

    def _verify_exec_terminal(self) -> bool:
        """Check if exec terminal still exists"""
        try:
            terminals = self.plugin_dbus.get_all_terminals_metadata()

            # Debug output for terminal verification
            self._debug(f"Looking for exec UUID: {repr(self.exec_terminal_uuid)} (type: {type(self.exec_terminal_uuid).__name__})")
            self._debug(f"Plugin returned {len(terminals)} terminals")
            for t in terminals:
                self._debug(f"  - {repr(t['uuid'])} (type: {type(t['uuid']).__name__}) | Title: {t.get('title', 'N/A')}")
                if t['uuid'] == self.exec_terminal_uuid:
                    self._debug("    ✓ EXACT MATCH!")

            # Normalize both sides for comparison
            exec_uuid_normalized = self._normalize_uuid(self.exec_terminal_uuid)
            return any(self._normalize_uuid(t['uuid']) == exec_uuid_normalized for t in terminals)
        except Exception as e:
            self._debug(f"Verification error: {e}")
            return False

    def _recreate_exec_terminal(self) -> bool:
        """Recreate exec terminal if closed"""
        try:
            self.console.print("[yellow]Recreating Exec terminal...[/]")

            # Get current focused terminal
            focused_terminal = self.dbus_service.get_focused_terminal()
            if not focused_terminal:
                raise Exception("No terminal is currently focused. Cannot recreate Exec terminal.")
            current_uuid = str(focused_terminal)

            # Create new exec terminal (split to the right)
            exec_uuid = self.dbus_service.vsplit(
                current_uuid,
                dbus.Dictionary({'title': 'Sidechat: Exec (Restored)'}, signature='ss')
            )
            if str(exec_uuid).startswith('ERROR'):
                raise Exception(f"Failed to split terminal: {exec_uuid}")

            self.exec_terminal_uuid = self._normalize_uuid(exec_uuid)
            self.console.print(f"[green]✓[/] Exec terminal restored: {exec_uuid[:8]}...")
            return True

        except Exception as e:
            self.console.print(f"[red]Failed to recreate exec terminal: {e}[/]")
            return False

    def intelligent_capture_with_stability(self, terminal_uuid, max_wait=None):
        """
        Capture terminal content with adaptive polling and stability detection.
        Waits for content to stop changing before returning.

        Args:
            terminal_uuid: Terminal to capture
            max_wait: Maximum wait time in seconds (uses config default if None)

        Returns:
            Tuple of (content, timed_out)
        """
        if max_wait is None:
            max_wait = self.capture_config['max_wait']

        # Get configuration
        initial_delay = self.capture_config['initial_delay']
        poll_interval = self.capture_config['poll_interval']
        max_poll_interval = self.capture_config['max_poll_interval']
        backoff_factor = self.capture_config['backoff_factor']
        stability_checks = self.capture_config['stability_checks']

        # Calculate max attempts based on timing
        max_attempts = int(max_wait / poll_interval) + 5

        # Initial delay for command to start executing
        time.sleep(initial_delay)

        # Track elapsed time for minimum wait enforcement
        start_time = time.time()

        previous_content = None
        stable_count = 0
        attempt = 0
        current_interval = poll_interval
        current_content = ""  # Initialize to avoid NameError if loop doesn't execute

        # Spinner animation characters
        spinner_chars = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]

        while attempt < max_attempts:
            # Capture current content
            try:
                current_content = self.plugin_dbus.capture_terminal_content(
                    terminal_uuid, -1
                )

                # DIAGNOSTIC: Log what we're getting
                if attempt == 0:
                    dbg_len = len(current_content) if current_content else 0
                    self.console.print(f"[dim]Initial capture: {dbg_len} chars[/dim]", end="\r")

            except dbus.exceptions.DBusException as e:
                # D-Bus communication error with plugin
                self.console.print(f"[red]Plugin D-Bus error: {e}[/red]")
                return ("", True)
            except Exception as e:
                # Other unexpected error
                self.console.print(f"[red]Capture error ({type(e).__name__}): {e}[/red]")
                return ("", True)

            # Check for stability with enhanced validation
            elapsed = time.time() - start_time
            min_wait = self.capture_config.get('min_wait_before_stability', 0.5)

            if current_content == previous_content:
                # Apply minimum wait before allowing stability detection
                if elapsed < min_wait:
                    # Too early - don't count toward stability yet
                    # Show why we're not accepting stability yet
                    sys.stdout.write(f"\r⏱  Too early for stability ({elapsed:.1f}s < {min_wait}s)   ")
                    sys.stdout.flush()
                else:
                    # Time constraint met, count this as a stable match
                    stable_count += 1

                if stable_count >= stability_checks:
                    # Content appears stable - validate with size heuristic
                    content_len = len(current_content) if current_content else 0

                    # If content is suspiciously small (< 400 chars), require extra confirmation
                    if content_len < 400 and elapsed < 1.5:
                        # Content looks incomplete - keep waiting
                        sys.stdout.write(f"\r⚠  Content small ({content_len} chars), waiting longer...   ")
                        sys.stdout.flush()
                        stable_count = stability_checks - 1  # Reset to need one more match
                    else:
                        # Content is stable and sufficient!
                        sys.stdout.write("\r" + " " * 60 + "\r")
                        sys.stdout.flush()
                        return (current_content, False)
            else:
                # Content changed, reset stability counter
                stable_count = 0
                previous_content = current_content

            # Visual feedback
            spinner = spinner_chars[attempt % len(spinner_chars)]
            stability_dots = "●" * stable_count + "○" * (stability_checks - stable_count)
            elapsed = initial_delay + sum([poll_interval * (backoff_factor ** i) for i in range(attempt)])
            sys.stdout.write(f"\r{spinner} Waiting for output {stability_dots} ({elapsed:.1f}s)")
            sys.stdout.flush()

            # Adaptive wait with exponential backoff
            time.sleep(current_interval)
            current_interval = min(current_interval * backoff_factor, max_poll_interval)
            attempt += 1

        # Timeout - clear feedback line, return last content
        sys.stdout.write("\r" + " " * 60 + "\r")
        sys.stdout.flush()
        return (current_content if current_content else "", True)

    def simple_snapshot_capture(self, terminal_uuid, lines=-1) -> str:
        """
        Simple direct snapshot of terminal content with no stability detection.

        This is ideal for:
        - TUI applications (htop, vim) that continuously update or wait for input
        - Watch mode captures (periodic snapshots)
        - Manual context captures

        Args:
            terminal_uuid: Terminal to capture
            lines: Number of lines to capture (-1 for auto-detect viewport)

        Returns:
            Terminal content as string
        """
        try:
            content = self.plugin_dbus.capture_terminal_content(terminal_uuid, lines)
            return content if content and not content.startswith('ERROR') else ""
        except Exception as e:
            self.console.print(f"[red]Snapshot capture error: {e}[/]")
            return ""

    def wait_for_tui_render(self, terminal_uuid, max_wait=2.0, initial_content=None) -> bool:
        """
        Wait for TUI application to finish rendering by detecting content stability.

        First waits for content to CHANGE from initial state (TUI starting),
        then waits for stability (TUI finished rendering).

        Args:
            terminal_uuid: Terminal to monitor
            max_wait: Maximum wait time in seconds (default: 2.0)
            initial_content: Terminal content before command was sent (for change detection)

        Returns:
            True if content stabilized, False if timed out
        """
        start_time = time.time()
        poll_interval = 0.15
        previous_content = None
        stable_count = 0
        content_changed = initial_content is None  # Skip change detection if no initial

        while time.time() - start_time < max_wait:
            try:
                current_content = self.plugin_dbus.capture_terminal_content(terminal_uuid, -1)

                # First, wait for content to change from initial state
                if not content_changed:
                    if current_content != initial_content:
                        content_changed = True
                        self._debug(f"TUI content changed after {time.time() - start_time:.2f}s")
                        previous_content = current_content
                    time.sleep(poll_interval)
                    continue

                # Then check for stability
                if current_content == previous_content:
                    stable_count += 1
                    if stable_count >= 2:  # Stable for 2 consecutive polls
                        self._debug(f"TUI render stabilized after {time.time() - start_time:.2f}s")
                        return True
                else:
                    stable_count = 0
                    previous_content = current_content

                time.sleep(poll_interval)
            except Exception as e:
                self._debug(f"TUI render wait error: {e}")
                time.sleep(poll_interval)

        self._debug(f"TUI render wait timed out after {max_wait}s")
        return False  # Timeout - proceed anyway

    def prompt_based_capture(self, terminal_uuid, max_wait=30, initial_content=None) -> Tuple[bool, str]:
        """
        Capture terminal content using prompt detection instead of stability checks.

        Polls terminal and stops when content has changed from initial state AND
        a shell prompt is detected at the end. This prevents false positives from
        the old prompt that was visible before the command started.

        Falls back to timeout for long-running commands or TUI applications.

        This is ideal for:
        - Command-line tools that return to prompt quickly
        - Exec terminal command execution
        - Cases where prompt detection is more reliable than stability

        Args:
            terminal_uuid: Terminal to capture
            max_wait: Maximum wait time in seconds (default: 30)
            initial_content: Terminal content before command was sent (for change detection)

        Returns:
            Tuple of (prompt_detected, content)
        """
        # Configuration
        initial_delay = 0.3
        poll_interval = 0.5
        max_attempts = int(max_wait / poll_interval)

        # Initial delay for command to start
        time.sleep(initial_delay)

        # Spinner animation
        spinner_chars = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]
        content_changed = initial_content is None  # If no initial content, skip change detection
        content = ""  # Initialize to avoid NameError if loop doesn't execute

        for attempt in range(max_attempts):
            try:
                content = self.plugin_dbus.capture_terminal_content(terminal_uuid, -1)

                # First, check if content has changed from initial state
                if not content_changed:
                    if content != initial_content:
                        content_changed = True
                        self._debug("Content changed from initial state")

                # Only check for prompt after content has changed
                if content_changed and content and PromptDetector.detect_prompt_at_end(content):
                    # Clear spinner and return
                    sys.stdout.write("\r" + " " * 60 + "\r")
                    sys.stdout.flush()
                    return (True, content)

                # Visual feedback
                spinner = spinner_chars[attempt % len(spinner_chars)]
                elapsed = initial_delay + (attempt * poll_interval)
                status = "Waiting for output" if not content_changed else "Waiting for prompt"
                sys.stdout.write(f"\r{spinner} {status} ({elapsed:.1f}s)")
                sys.stdout.flush()

                time.sleep(poll_interval)

            except dbus.exceptions.DBusException as e:
                self.console.print(f"[red]Plugin D-Bus error during capture: {e}[/]")
                return (False, "")
            except Exception as e:
                self.console.print(f"[red]Prompt-based capture error ({type(e).__name__}): {e}[/]")
                return (False, "")

        # Timeout - return last content
        sys.stdout.write("\r" + " " * 60 + "\r")
        sys.stdout.flush()
        return (False, content if content else "")

    def capture_context(self, include_exec_output=False) -> Tuple[str, List[llm.Attachment]]:
        """
        Capture visible content from all terminals (like tmuxai).

        Excludes:
        - Chat terminal (where sidechat is running) - to avoid self-reference
        - Exec terminal (unless include_exec_output=True)

        For TUI applications (htop, glances, vim, etc.), captures screenshots
        instead of text since TUI content doesn't extract well as plain text.

        Returns:
            Tuple of (context_string, attachments_list):
            - context_string: XML-wrapped text content for non-TUI terminals
            - attachments_list: Screenshot attachments for TUI terminals
        """
        import base64

        try:
            terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
            context_parts = []
            attachments = []

            for term in terminals:
                term_uuid = self._normalize_uuid(term['uuid'])

                # Skip chat terminal (self-awareness)
                if term_uuid == self.chat_terminal_uuid:
                    continue

                # Optionally skip exec terminal
                if not include_exec_output and term_uuid == self.exec_terminal_uuid:
                    continue

                # Check if TUI is active in this terminal
                is_tui = False
                try:
                    is_tui = self.plugin_dbus.is_likely_tui_active(term['uuid'])
                except Exception:
                    pass  # Fall back to text capture if TUI detection fails

                if is_tui:
                    # Capture screenshot for TUI terminal
                    self._debug(f"TUI detected in terminal {term['title']}, capturing screenshot")
                    try:
                        screenshot_data = self.plugin_dbus.capture_terminal_screenshot(term['uuid'])
                        if screenshot_data and not screenshot_data.startswith('ERROR'):
                            # Save to temp file and create attachment
                            image_bytes = base64.b64decode(screenshot_data)
                            temp_path = os.path.join(
                                tempfile.gettempdir(),
                                f"sidechat_ctx_{term_uuid[:8]}_{int(time.time()*1000)}.png"
                            )
                            with open(temp_path, 'wb') as f:
                                f.write(image_bytes)
                            self.screenshot_files.append(temp_path)
                            attachments.append(llm.Attachment(path=temp_path))
                            # Add marker in context so AI knows about the screenshot
                            context_parts.append(f'<terminal uuid="{term_uuid}" title="{term["title"]}" type="tui-screenshot">Screenshot attached for this TUI terminal</terminal>')
                            continue  # Don't fall through to text capture
                        else:
                            self._debug(f"Screenshot failed for {term['title']}: {screenshot_data}")
                    except Exception as e:
                        self._debug(f"TUI screenshot failed for {term['title']}: {e}")
                    # Fall through to text capture if screenshot fails

                # Regular text capture for non-TUI terminals (or TUI fallback)
                content = self.plugin_dbus.capture_terminal_content(term['uuid'], -1)

                if content and not content.startswith('ERROR'):
                    # Format like tmux-fragments
                    context_parts.append(f'''<terminal uuid="{term['uuid']}" title="{term['title']}" cwd="{term['cwd']}">
{content}
</terminal>''')

            return "\n\n".join(context_parts), attachments
        except Exception as e:
            self.console.print(f"[red]Error capturing context: {e}[/]")
            return "", []

    def capture_context_intelligent(self, include_exec_output=False) -> Tuple[str, List[llm.Attachment]]:
        """
        Capture context with intelligent stability detection.
        Uses adaptive polling to wait for terminal output to stabilize.

        For TUI applications, captures screenshots instead of text since TUI
        content doesn't stabilize well with text-based capture.

        Args:
            include_exec_output: If True, include exec terminal content

        Returns:
            Tuple of (context_string, attachments_list):
            - context_string: XML-wrapped text content for non-TUI terminals
            - attachments_list: Screenshot attachments for TUI terminals
        """
        import base64

        try:
            terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
            context_parts = []
            attachments = []
            timeout_warnings = []

            for term in terminals:
                uuid = self._normalize_uuid(term.get('uuid'))

                # Skip chat terminal (self-awareness)
                if uuid == self.chat_terminal_uuid:
                    continue

                # Optionally skip exec terminal
                if not include_exec_output and uuid == self.exec_terminal_uuid:
                    continue

                # Check if TUI is active in this terminal
                is_tui = False
                try:
                    is_tui = self.plugin_dbus.is_likely_tui_active(term['uuid'])
                except Exception:
                    pass  # Fall back to text capture if TUI detection fails

                if is_tui:
                    # Capture screenshot for TUI terminal (no stability detection needed)
                    self._debug(f"TUI detected in terminal {term['title']}, capturing screenshot")
                    try:
                        screenshot_data = self.plugin_dbus.capture_terminal_screenshot(term['uuid'])
                        if screenshot_data and not screenshot_data.startswith('ERROR'):
                            # Save to temp file and create attachment
                            image_bytes = base64.b64decode(screenshot_data)
                            temp_path = os.path.join(
                                tempfile.gettempdir(),
                                f"sidechat_ctx_{uuid[:8]}_{int(time.time()*1000)}.png"
                            )
                            with open(temp_path, 'wb') as f:
                                f.write(image_bytes)
                            self.screenshot_files.append(temp_path)
                            attachments.append(llm.Attachment(path=temp_path))
                            context_parts.append(f'<terminal uuid="{uuid}" title="{term["title"]}" type="tui-screenshot">Screenshot attached for this TUI terminal</terminal>')
                            continue  # Don't fall through to text capture
                        else:
                            self._debug(f"Screenshot failed for {term['title']}: {screenshot_data}")
                    except Exception as e:
                        self._debug(f"TUI screenshot failed for {term['title']}: {e}")
                    # Fall through to text capture if screenshot fails

                # Intelligent capture with stability detection for non-TUI terminals
                content, timed_out = self.intelligent_capture_with_stability(uuid)

                if timed_out:
                    timeout_warnings.append(term.get('title', 'Unknown'))

                if content and not content.startswith('ERROR'):
                    # Format like tmux-fragments
                    context_parts.append(f'''<terminal uuid="{uuid}" title="{term['title']}" cwd="{term['cwd']}">
{content}
</terminal>''')

            # Show timeout warnings if any
            if timeout_warnings:
                warning_msg = ", ".join(timeout_warnings)
                self.console.print(f"[yellow]⚠ Capture timeout: {warning_msg}[/yellow]")

            return "\n\n".join(context_parts), attachments
        except Exception as e:
            self.console.print(f"[red]Error capturing context: {e}[/]")
            return "", []

    def estimate_tokens(self) -> int:
        """Estimate token count from conversation responses and system prompt.

        Uses incremental caching to avoid O(n) recalculation on every call.
        Only counts new responses since last cache update.
        """
        try:
            current_response_count = len(self.conversation.responses)

            # If conversation was reset/squashed (fewer responses), reset cache
            if current_response_count < self._cached_response_count:
                self._cached_token_count = len(self.system_prompt)
                self._cached_response_count = 0

            # If no new responses, return cached value
            if current_response_count == self._cached_response_count:
                # Ensure system prompt is counted even with no responses
                if self._cached_token_count == 0:
                    self._cached_token_count = len(self.system_prompt)
                return self._cached_token_count // 4

            # Count only NEW responses (incremental update)
            new_chars = 0
            for response in self.conversation.responses[self._cached_response_count:]:
                # Count the prompt
                if hasattr(response, 'prompt'):
                    prompt_obj = response.prompt
                    if hasattr(prompt_obj, 'prompt'):
                        new_chars += len(str(prompt_obj.prompt))
                    if hasattr(prompt_obj, 'system') and prompt_obj.system:
                        new_chars += len(str(prompt_obj.system))

                # Count the response text
                # NOTE: Accessing internal llm library attribute '_chunks' for response text.
                # This is fragile and may break if llm library internals change.
                # hasattr check provides graceful degradation if attribute is removed.
                if hasattr(response, '_chunks'):
                    new_chars += sum(len(chunk) for chunk in response._chunks)
                else:
                    # Warn about API degradation (only once per session)
                    if not hasattr(self, '_api_warning_shown'):
                        self.console.print("[yellow]⚠ Warning: Token estimation using fallback (llm API may have changed)[/]")
                        self._api_warning_shown = True
                    # Fallback: use response.text() length
                    try:
                        new_chars += len(response.text())
                    except Exception:
                        pass  # Silently skip if text() also unavailable

            # Update cache (add system prompt on first count)
            if self._cached_response_count == 0 and self._cached_token_count == 0:
                self._cached_token_count = len(self.system_prompt)
            self._cached_token_count += new_chars
            self._cached_response_count = current_response_count

            return self._cached_token_count // 4

        except Exception as e:
            self.console.print(f"[yellow]Warning: Token estimation failed: {e}[/]")
            # Fallback: estimate from conversation object
            try:
                total_chars = len(self.system_prompt)
                for resp in self.conversation.responses:
                    total_chars += len(str(resp))
                return total_chars // 4
            except Exception:
                # Ultimate fallback: use fixed estimate
                return len(self.conversation.responses) * 1000  # ~1000 tokens per exchange

    def check_and_squash_context(self):
        """Auto-squash when context reaches threshold (like tmuxai)"""
        current_tokens = self.estimate_tokens()

        if current_tokens >= self.max_context_size * self.context_squash_threshold:
            self.console.print("[yellow]Context approaching limit, auto-squashing...[/]")
            self.squash_context()

    def squash_context(self):
        """Compress earlier messages into summary (like tmuxai)"""
        if len(self.conversation.responses) <= 5:  # Keep at least 5 recent exchanges
            self.console.print("[yellow]Too few messages to squash[/]")
            return

        try:
            # Get responses to squash (all but last 3 - we'll re-execute those)
            responses_to_squash = self.conversation.responses[:-3]

            # Build summary from old responses
            summary_parts = []
            for i, response in enumerate(responses_to_squash, 1):
                # Extract prompt text
                # NOTE: Accessing internal llm library attributes '_prompt' and '_chunks'.
                # This is fragile and may break if llm library internals change.
                prompt_text = ""
                if hasattr(response, 'prompt'):
                    if hasattr(response.prompt, '_prompt'):
                        prompt_text = response.prompt._prompt or ""
                    elif hasattr(response.prompt, 'prompt'):
                        # Try public API first
                        prompt_text = str(response.prompt.prompt) or ""
                    else:
                        # Fallback: stringify entire prompt object
                        try:
                            prompt_text = str(response.prompt)[:500]  # Limit length
                        except:
                            prompt_text = "[prompt unavailable]"

                # Extract response text
                response_text = ""
                if hasattr(response, '_chunks'):
                    response_text = "".join(response._chunks)
                elif hasattr(response, 'text'):
                    # Fallback to public text() method
                    try:
                        response_text = response.text()
                    except:
                        response_text = "[response unavailable]"
                else:
                    response_text = str(response)[:500]  # Last resort

                if prompt_text:
                    summary_parts.append(f"{i}. User: {prompt_text[:200]}...")
                if response_text:
                    summary_parts.append(f"{i}. AI: {response_text[:200]}...")

            # Generate summary using a standalone prompt (not in conversation)
            summary_prompt = f"""Summarize this conversation history concisely, focusing on:
- Key technical issues discussed
- Commands executed and their results
- Important decisions or insights
- Relevant context for continuing the conversation

Previous messages:
{chr(10).join(summary_parts)}

Provide a brief but comprehensive summary."""

            summary_response = self.model.prompt(summary_prompt)
            summary = summary_response.text()

            # Create new conversation and update system prompt
            # Build enhanced system prompt from ORIGINAL, not current
            # This prevents infinite growth when squashing multiple times
            self.system_prompt = f"""{self.original_system_prompt}

[Previous conversation summary]
{summary}
[End of summary]"""

            # Create completely fresh conversation
            # We'll pass the new system prompt on the next user interaction
            self.conversation = llm.Conversation(model=self.model)

            new_tokens = self.estimate_tokens()
            self.console.print(f"[green]✓[/] Context squashed: ~{new_tokens} tokens")
            self.console.print(f"[cyan]Started fresh conversation with summary in system prompt[/]")

        except Exception as e:
            self.console.print(f"[red]Error squashing context: {e}[/]")

    def extract_commands(self, text: str) -> List[str]:
        """Extract commands from <EXECUTE>...</EXECUTE> XML tags.

        Each <EXECUTE> tag contains one command to execute.
        Multi-line content within a single tag is split into separate commands.
        """
        matches = EXECUTE_PATTERN.findall(text)

        commands = []
        for block in matches:
            # Split multi-line blocks into individual commands
            for line in block.split('\n'):
                line = line.strip()
                # Skip empty lines and comments
                if not line or line.startswith('#'):
                    continue
                commands.append(line)

        return commands

    def escape_action_tags_for_display(self, text: str) -> str:
        """Remove XML action tags, show only content in backticks.

        <EXECUTE>cmd</EXECUTE> → `cmd`
        <PRESSKEY>q</PRESSKEY> → `q`
        """
        # Replace content tags with backtick-wrapped content
        text = EXECUTE_PATTERN.sub(r'`\1`', text)
        text = PRESSKEY_PATTERN.sub(r'`\1`', text)
        # Replace self-closing tags with placeholder
        text = re.sub(r'<CAPTURE(?:>.*?</CAPTURE>|/?>)', '`[capture]`', text, flags=re.IGNORECASE)
        text = re.sub(r'<REFRESH/?>', '`[refresh]`', text, flags=re.IGNORECASE)
        return text

    def extract_keypresses(self, text: str) -> List[str]:
        """Extract keypresses from <PRESSKEY>...</PRESSKEY> XML tags.

        Each <PRESSKEY> tag contains one keypress to send.
        Examples: <PRESSKEY>Ctrl+C</PRESSKEY>, <PRESSKEY>:wq</PRESSKEY>, <PRESSKEY>Enter</PRESSKEY>
        """
        matches = PRESSKEY_PATTERN.findall(text)
        return [kp.strip() for kp in matches if kp.strip()]

    def extract_screenshot_requests(self, text: str) -> List[str]:
        """Extract screenshot requests from <CAPTURE/> XML tags.

        Returns list of screenshot types:
        - 'exec' for <CAPTURE/> (default - exec terminal only)
        - 'all' for <CAPTURE>all</CAPTURE> (all terminals)
        """
        matches = SCREENSHOT_REQUEST_PATTERN.findall(text)
        # findall returns the capture group (the 'all' part or empty string)
        return ['all' if m and m.lower() == 'all' else 'exec' for m in matches] if matches else []

    def extract_context_refresh_requests(self, text: str) -> bool:
        """Check if text contains a context refresh request <REFRESH/>"""
        return bool(CONTEXT_REFRESH_PATTERN.search(text))

    def process_fragments(self, prompt: str):
        """
        Process !fragment commands in a prompt and return modified prompt plus resolved fragments.
        Based on llm.cli.process_fragments_in_chat

        Returns:
            (modified_prompt, fragments): Tuple of prompt text and list of Fragment objects
        """
        prompt_lines = []
        fragments = []

        for line in prompt.splitlines():
            if line.startswith("!fragment "):
                try:
                    fragment_strs = line.strip().removeprefix("!fragment ").split()
                    # Get llm database
                    db = llm.get_default_db()
                    # Resolve fragments
                    resolved = resolve_fragments(db, fragments=fragment_strs, allow_attachments=False)
                    fragments.extend(resolved)
                except FragmentNotFound as ex:
                    self.console.print(f"[red]Fragment error: {ex}[/]")
                    # Don't include the !fragment line but continue processing
                except Exception as ex:
                    self.console.print(f"[red]Error processing fragment: {ex}[/]")
            else:
                prompt_lines.append(line)

        return "\n".join(prompt_lines), fragments

    def wait_for_command_completion(self, timeout=30) -> Tuple[bool, str]:
        """
        Wait for command to complete using intelligent capture with stability detection.

        Returns:
            (completed, output): Boolean + captured output
        """
        try:
            # Use intelligent capture with stability detection
            # This handles timing, polling, and content validation automatically
            content, timed_out = self.intelligent_capture_with_stability(
                self.exec_terminal_uuid,
                max_wait=timeout
            )

            if timed_out:
                # Timeout occurred, but return whatever we captured
                return (False, content)

            # Content is stable - verify it looks reasonable
            if content and len(content) > 100:
                # Sanity check: verify prompt markers are present
                # This confirms command completed and shell is ready
                if PromptDetector.detect_prompt_at_end(content):
                    return (True, content)
                else:
                    # Content stable but no clear prompt - might be TUI or long output
                    # Still consider it successful
                    return (True, content)
            else:
                # Very short content - might be problematic
                return (False, content)

        except Exception as e:
            self.console.print(f"[yellow]Error during command wait: {e}[/]")
            return (False, "")

    def should_use_screenshot_capture(self, command: str) -> bool:
        """
        Determine if screenshot capture should be used instead of text capture.

        Uses hybrid detection approach:
        1. Command-based detection (known TUI commands)
        2. Terminal state detection (alternate screen buffer heuristic)

        This provides better accuracy than command-based detection alone,
        catching cases where a TUI is launched via script or alias.

        Args:
            command: The command being executed

        Returns:
            True if screenshot capture should be used, False for text capture
        """
        # First check: known TUI command
        if is_tui_command(command):
            self._debug(f"TUI detected via command name: {command.split()[0] if command else ''}")
            return True

        # Second check: terminal state suggests TUI is active
        # This catches TUIs launched via scripts, aliases, or complex pipelines
        try:
            is_tui_active = self.plugin_dbus.is_likely_tui_active(self.exec_terminal_uuid)
            if is_tui_active:
                self._debug("TUI detected via terminal state (alternate screen heuristic)")
                self.console.print("[cyan]TUI detected via terminal state[/]")
                return True
        except dbus.exceptions.DBusException as e:
            # Method might not exist in older plugin versions
            self._debug(f"TUI state detection unavailable: {e}")
        except Exception as e:
            # Fall back to command-based detection only
            self._debug(f"TUI state detection error: {e}")

        return False

    def execute_command(self, command: str) -> Tuple[bool, str]:
        """
        Execute command in Exec terminal with user approval and intelligent completion detection.

        Returns:
            Tuple of (executed: bool, output: str or tuple)
        """
        self.console.print(Panel(
            Text(command, style="bold cyan"),
            title="[bold]Command to Execute[/]",
            border_style="cyan"
        ))

        # Ask for approval
        choice = Prompt.ask(
            "Execute in Exec terminal?",
            choices=["y", "n", "e"],  # yes, no, edit
            default="y"
        )

        if choice == "n":
            return (False, "")

        if choice == "e":
            # Allow editing
            edited = Prompt.ask("Edit command", default=command)
            command = edited

        # Verify exec terminal exists
        if not self._verify_exec_terminal():
            self.console.print("[yellow]Exec terminal not found[/]")
            if not self._recreate_exec_terminal():
                return (False, "")

        # Capture terminal content BEFORE sending command (for change detection)
        try:
            initial_content = self.plugin_dbus.capture_terminal_content(
                self.exec_terminal_uuid, -1
            )
        except Exception:
            initial_content = None  # Fallback: skip change detection

        # Send to Exec terminal
        try:
            success = self.plugin_dbus.send_keys_to_terminal(
                self.exec_terminal_uuid,
                command,
                execute=True
            )

            if success:
                self.console.print("[green]✓[/] Command sent to Exec terminal")

                # Detect if this is a TUI application using hybrid detection
                # Checks both command name AND terminal state (alternate screen heuristic)
                if self.should_use_screenshot_capture(command):
                    # TUI detected - use screenshot capture
                    self.console.print("[cyan]TUI application detected - using screenshot capture[/]")

                    # Adaptive wait for TUI to render (replaces fixed 1.5s delay)
                    # Pass initial_content so we wait for content to change first
                    self.wait_for_tui_render(self.exec_terminal_uuid, max_wait=2.0, initial_content=initial_content)

                    try:
                        # Capture screenshot via plugin
                        screenshot_data = self.plugin_dbus.capture_terminal_screenshot(
                            self.exec_terminal_uuid
                        )

                        if screenshot_data.startswith('ERROR'):
                            # Escape brackets in error message for Rich markup
                            escaped_error = screenshot_data.replace('[', '[[').replace(']', ']]')
                            self.console.print(f"[red]{escaped_error}[/]")
                            return True, f"Screenshot capture failed: {screenshot_data}"

                        # Save screenshot to temporary file
                        import base64
                        image_bytes = base64.b64decode(screenshot_data)

                        temp_path = os.path.join(tempfile.gettempdir(), f"sidechat_screenshot_{int(time.time())}.png")
                        with open(temp_path, 'wb') as f:
                            f.write(image_bytes)

                        # Track screenshot for cleanup on exit
                        self.screenshot_files.append(temp_path)

                        self.console.print(f"[green]✓[/] TUI screenshot captured: {temp_path}")

                        # Return a message with the screenshot path
                        # The AI will be able to see this image via attachments
                        output = f"""TUI application screenshot saved to: {temp_path}

This is an interactive TUI application (like htop, vim, or less). The screenshot shows its current display state.

Screenshot size: {len(image_bytes)} bytes"""

                        return True, (output, temp_path)  # Return both text and image path

                    except Exception as e:
                        # Escape brackets in exception message for Rich markup
                        escaped_error = str(e).replace('[', '[[').replace(']', ']]')
                        self.console.print(f"[red]Screenshot capture error: {escaped_error}[/]")
                        return True, f"Screenshot capture failed: {e}"
                else:
                    # Regular command - use prompt-based capture
                    prompt_detected, output = self.prompt_based_capture(
                        self.exec_terminal_uuid,
                        max_wait=30,
                        initial_content=initial_content
                    )

                    if prompt_detected:
                        self.console.print("[green]✓[/] Command completed (prompt detected)")
                        return True, output
                    else:
                        self.console.print("[yellow]⚠[/] Timeout or long-running command")

                        # Post-timeout TUI check: command may have launched a TUI we didn't expect
                        # (e.g., git log with pager, script that invokes vim, etc.)
                        try:
                            if self.plugin_dbus.is_likely_tui_active(self.exec_terminal_uuid):
                                self.console.print("[cyan]TUI detected after timeout - capturing screenshot[/]")
                                import base64
                                screenshot_data = self.plugin_dbus.capture_terminal_screenshot(self.exec_terminal_uuid)
                                if screenshot_data and not screenshot_data.startswith('ERROR'):
                                    image_bytes = base64.b64decode(screenshot_data)
                                    temp_path = os.path.join(tempfile.gettempdir(), f"sidechat_screenshot_{int(time.time())}.png")
                                    with open(temp_path, 'wb') as f:
                                        f.write(image_bytes)
                                    self.screenshot_files.append(temp_path)
                                    self.console.print(f"[green]✓[/] TUI screenshot captured: {temp_path}")
                                    return True, (output, temp_path)  # Return with screenshot
                        except Exception as e:
                            self._debug(f"Post-timeout TUI check failed: {e}")

                        return True, output
            else:
                self.console.print("[red]✗[/] Failed to send command")
                return False, ""
        except dbus.exceptions.DBusException as e:
            self.console.print(f"[red]D-Bus error executing command: {e}[/]")
            self.console.print("[yellow]Plugin may have disconnected. Try /reset[/]")
            return False, ""
        except Exception as e:
            self.console.print(f"[red]Error executing command ({type(e).__name__}): {e}[/]")
            return False, ""

    def execute_keypress(self, keypress: str) -> bool:
        """
        Send keypress to Exec terminal with user approval.
        Does NOT automatically execute (no newline unless keypress is "Enter").

        Returns:
            True if sent, False if skipped
        """
        self.console.print(Panel(
            Text(f"[▸] {keypress}", style="bold magenta"),
            title="[bold]Keypress to Send[/]",
            border_style="magenta"
        ))

        # Ask for approval
        choice = Prompt.ask(
            "Send this key(s)?",
            choices=["y", "n", "e"],  # yes, no, edit
            default="y"
        )

        if choice == "n":
            return False

        if choice == "e":
            # Allow editing
            edited = Prompt.ask("Edit keypress", default=keypress)
            keypress = edited

        # Verify exec terminal exists
        if not self._verify_exec_terminal():
            self.console.print("[yellow]Exec terminal not found[/]")
            if not self._recreate_exec_terminal():
                return False

        # Send keypress to Exec terminal using new D-Bus method
        try:
            success = self.plugin_dbus.send_keypress_to_terminal(
                self.exec_terminal_uuid,
                keypress
            )

            if success:
                self.console.print(f"[green]✓[/] Keypress '{keypress}' sent to Exec terminal")
                return True
            else:
                self.console.print("[red]✗[/] Failed to send keypress")
                return False
        except Exception as e:
            self.console.print(f"[red]Error sending keypress: {e}[/]")
            return False

    def _compute_context_hash(self, context: str, attachments: List[llm.Attachment]) -> str:
        """Compute SHA256 hash of context for change detection."""
        hasher = hashlib.sha256()
        normalized_context = ' '.join(context.split())  # Normalize whitespace
        hasher.update(normalized_context.encode('utf-8'))
        for attachment in attachments:
            if hasattr(attachment, 'path') and attachment.path:
                hasher.update(attachment.path.encode('utf-8'))
        return hasher.hexdigest()

    def _is_watch_response_dismissive(self, response_text: str) -> bool:
        """Determine if response indicates no action needed."""
        if not response_text:
            return True
        normalized = response_text.strip().lower().rstrip('.')
        dismissive_exact = {
            'ok', 'okay', 'k', 'no comment', 'no issues', 'nothing to report',
            'nothing new', 'all good', 'looks good', 'no action needed',
            'no changes', 'nothing notable', 'nothing unusual', 'all normal',
        }
        if normalized in dismissive_exact:
            return True
        # Short positive responses (1-3 words) are likely dismissive
        words = normalized.split()
        if len(words) <= 3:
            positive = {'ok', 'okay', 'good', 'fine', 'normal', 'clear', 'stable'}
            if any(word in positive for word in words):
                return True
        return False

    def _start_watch_mode_thread(self):
        """Start watch mode in a background thread with its own event loop"""
        def watch_thread_target():
            self.event_loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.event_loop)
            try:
                self.watch_task = self.event_loop.create_task(self.watch_loop())
                self.event_loop.run_until_complete(self.watch_task)
            except asyncio.CancelledError:
                pass  # Expected when watch mode is disabled
            except Exception as e:
                self.console.print(f"[red]Watch mode error: {e}[/]")
            finally:
                self.watch_task = None
                self.event_loop.close()

        self.watch_thread = threading.Thread(target=watch_thread_target, daemon=True)
        self.watch_thread.start()

    async def watch_loop(self):
        """
        Background monitoring of all terminals (like tmuxai watch mode).

        Implements intelligent change detection:
        1. Hash-based skip: Don't send unchanged context to AI
        2. History-aware prompt: Tell AI to focus on NEW content when changes detected
        """
        while self.watch_mode:
            try:
                # Thread-safe capture and prompt - hold lock during D-Bus calls and conversation
                # This prevents race conditions with main thread's D-Bus operations
                context = None
                tui_attachments = []
                response_text = None
                exec_status = ""
                should_skip = False

                with self.watch_lock:
                    # Capture all terminal content (including exec output for watch)
                    # Returns (context_text, tui_attachments) tuple for TUI screenshot support
                    context, tui_attachments = self.capture_context(include_exec_output=True)

                    # Check exec terminal idle state using PromptDetector
                    try:
                        exec_content = self.plugin_dbus.capture_terminal_content(
                            self.exec_terminal_uuid, -1
                        )
                        if exec_content:
                            is_idle = PromptDetector.detect_prompt_at_end(exec_content)
                            exec_status = "[Exec: idle]" if is_idle else "[Exec: command running]"
                    except Exception:
                        exec_status = "[Exec: unknown]"

                    if not context.strip():
                        # No context to analyze
                        should_skip = True
                    else:
                        # CHANGE DETECTION: Compute hash and compare with previous
                        current_hash = self._compute_context_hash(context, tui_attachments)

                        if current_hash == self.previous_watch_context_hash:
                            # Context unchanged - skip AI call entirely
                            should_skip = True
                        else:
                            # Context changed - update hash and proceed
                            self.previous_watch_context_hash = current_hash
                            self.previous_watch_iteration_count += 1

                            # HISTORY-AWARE PROMPT: Tell AI to focus on new content
                            prompt = f"""[Watch Mode - Iteration {self.previous_watch_iteration_count}] Goal: {self.watch_goal}
{exec_status}

IMPORTANT: Compare this terminal state against the conversation history above.
Focus ONLY on content that has changed or is NEW since your last watch observation.
Do not comment on content you have already analyzed in previous iterations.

Current terminal state:
{context}

Instructions:
1. Identify what has CHANGED since your last observation (use conversation history for reference)
2. If changes are relevant to the watch goal "{self.watch_goal}", provide actionable suggestions
3. If no relevant NEW content, respond with only "OK"
4. Keep responses concise - focus on actionable insights only"""

                            try:
                                # Include TUI screenshots if any were captured
                                response = self.conversation.prompt(prompt, attachments=tui_attachments if tui_attachments else None)
                                # Consume response while holding lock to prevent concurrent modifications
                                response_text = response.text()
                            except Exception as response_error:
                                # Don't update hash on error - will retry next iteration
                                self.previous_watch_context_hash = None
                                self.console.print(f"[yellow]Watch mode response error: {response_error}[/]")

                # Only show if AI has actionable feedback - outside lock
                if not should_skip and response_text and response_text.strip():
                    if not self._is_watch_response_dismissive(response_text):
                        self.console.print()
                        self.console.print(Panel(
                            Markdown(response_text),
                            title="[bold yellow]Watch Mode Alert[/]",
                            border_style="yellow"
                        ))
                        self.console.print()

            except Exception as e:
                self.console.print(f"[red]Watch mode error: {e}[/]")

            await asyncio.sleep(self.watch_interval)

    def handle_slash_command(self, command: str) -> bool:
        """
        Handle slash commands.

        Returns:
            True if should continue REPL, False to exit
        """
        parts = command.split(maxsplit=1)
        cmd = parts[0].lower()
        args = parts[1] if len(parts) > 1 else ""

        if cmd == "/help":
            self.console.print(Panel("""
[bold]Available Commands:[/]

/help              Show this help message
/clear             Clear conversation history
/reset             Full reset: clear history and remove squash summaries
/refresh           Refresh terminal context (re-capture current state)
/model <name>      Switch model or list available models
/info              Show session information
/watch <goal>      Enable watch mode with goal
/watch off         Disable watch mode
/watch status      Show watch mode status
/squash            Manually compress conversation context
/quit or /exit     Exit sidechat

[bold]Usage:[/]
- Type messages to chat with AI
- AI provides commands in <EXECUTE> tags
- Commands are sent to Exec terminal with approval
""", title="Sidechat Help", border_style="cyan"))
            return True

        elif cmd == "/clear":
            # Reset conversation (system prompt will be passed on next interaction)
            try:
                self.conversation = llm.Conversation(model=self.model)
                self.console.print("[green]✓[/] Conversation cleared")
            except Exception as e:
                self.console.print(f"[red]Error clearing conversation: {e}[/]")
            return True

        elif cmd == "/reset":
            # Clear conversation and reset terminal states (like tmuxai /reset)
            try:
                # Clear conversation
                self.conversation = llm.Conversation(model=self.model)

                # Reset system prompt to original
                self.system_prompt = self.original_system_prompt

                # Disable watch mode if active
                if self.watch_mode:
                    with self.watch_lock:
                        self.watch_mode = False
                        self.watch_goal = None
                        if self.event_loop and not self.event_loop.is_closed():
                            try:
                                self.event_loop.call_soon_threadsafe(self.event_loop.stop)
                            except RuntimeError:
                                pass  # Loop already closed

                # Clear plugin cache
                if hasattr(self, 'plugin_dbus') and self.plugin_dbus:
                    self.plugin_dbus.clear_cache()

                self.console.print("[green]✓[/] Conversation cleared and terminal states reset")
            except Exception as e:
                self.console.print(f"[red]Error resetting: {e}[/]")
            return True

        elif cmd == "/refresh":
            # Re-capture terminal content and show preview
            self.console.print("[cyan]Refreshing terminal context...[/]")

            # Clear plugin cache
            try:
                self.plugin_dbus.clear_cache()
            except Exception:
                pass

            # Simple snapshot capture (includes exec terminal)
            # Returns (context_text, tui_attachments) tuple for TUI screenshot support
            # Use watch_lock to avoid racing with watch mode (thread-safe)
            with self.watch_lock:
                context, tui_attachments = self.capture_context(include_exec_output=True)

            if context or tui_attachments:
                self.console.print(f"[green]✓[/] Captured {len(context)} characters of context")

                # Show TUI screenshots info
                if tui_attachments:
                    self.console.print(f"[green]✓[/] Captured {len(tui_attachments)} TUI screenshot(s)")

                # Show per-terminal breakdown
                import re
                terminals = re.findall(r'<terminal uuid="([^"]+)" title="([^"]+)"', context)
                if terminals:
                    self.console.print("\n[bold]Terminals captured:[/]")
                    for uuid_match, title in terminals:
                        # Check if this is a TUI screenshot
                        tui_pattern = rf'<terminal uuid="{re.escape(uuid_match)}"[^>]*type="tui-screenshot"'
                        if re.search(tui_pattern, context):
                            self.console.print(f"  • [cyan]{title}[/]: [magenta]TUI screenshot[/]")
                        else:
                            # Extract content for this terminal
                            term_pattern = rf'<terminal uuid="{re.escape(uuid_match)}"[^>]*>(.*?)</terminal>'
                            term_match = re.search(term_pattern, context, re.DOTALL)
                            if term_match:
                                term_content = term_match.group(1).strip()
                                lines = len([l for l in term_content.split('\n') if l.strip()])
                                chars = len(term_content)
                                self.console.print(f"  • [cyan]{title}[/]: {lines} lines, {chars} chars")

                # Show preview of first terminal (skip if only TUI screenshots)
                text_only = re.sub(r'<terminal[^>]*type="tui-screenshot"[^>]*>.*?</terminal>', '', context, flags=re.DOTALL)
                if text_only.strip():
                    self.console.print("\n[dim]First 300 chars of text content:[/]")
                    preview = text_only[:300].replace('\n', ' ')
                    self.console.print(f"[dim]{preview}...[/]")
            else:
                self.console.print("[yellow]No context captured[/]")

            return True

        elif cmd == "/model":
            if not args:
                # List available models
                self.console.print("[bold]Available models:[/]")
                for model in llm.get_models():
                    current = " [green](current)[/]" if model.model_id == self.model_name else ""
                    self.console.print(f"  - {model.model_id}{current}")
            else:
                # Switch model
                try:
                    self.model = llm.get_model(args)
                    self.model_name = args
                    self.console.print(f"[green]✓[/] Switched to model: {args}")

                    # Update conversation model
                    self.conversation.model = self.model
                except Exception as e:
                    self.console.print(f"[red]Error switching model: {e}[/]")
            return True

        elif cmd == "/info":
            tokens = self.estimate_tokens()
            percentage = (tokens * 100 // self.max_context_size) if self.max_context_size > 0 else 0
            self.console.print(Panel(f"""
[bold]Session Information:[/]

Model: {self.model_name}
Context size: ~{tokens:,} tokens / {self.max_context_size:,} ({percentage}%)
Exchanges: {len(self.conversation.responses)}
Watch mode: {"enabled" if self.watch_mode else "disabled"}
{f"Watch goal: {self.watch_goal}" if self.watch_mode else ""}

Chat terminal: {self.chat_terminal_uuid[:16]}...
Exec terminal: {self.exec_terminal_uuid[:16]}...
""", title="Session Info", border_style="cyan"))
            return True

        elif cmd == "/watch":
            if not args:
                # No args: show status with usage hint
                if self.watch_mode:
                    self.console.print(f"[green]Watch mode: enabled[/]")
                    self.console.print(f"Goal: {self.watch_goal}")
                    self.console.print(f"Interval: {self.watch_interval}s")
                else:
                    self.console.print("[yellow]Watch mode: disabled[/]")
                    self.console.print("[dim]Usage: /watch <goal> to enable[/]")
            elif args.lower() == "off":
                # Disable watch mode
                if self.watch_mode:
                    with self.watch_lock:
                        self.watch_mode = False
                        # Reset state for next enable
                        self.previous_watch_context_hash = None
                        self.previous_watch_iteration_count = 0
                        if self.watch_task and not self.watch_task.done():
                            # Cancel the task gracefully (interrupts asyncio.sleep)
                            try:
                                self.event_loop.call_soon_threadsafe(self.watch_task.cancel)
                            except RuntimeError:
                                pass  # Loop already closed
                    # Wait for watch thread to finish (prevents multiple threads)
                    if self.watch_thread and self.watch_thread.is_alive():
                        self.watch_thread.join(timeout=2.0)
                    self.console.print("[yellow]Watch mode disabled[/]")
                else:
                    self.console.print("[yellow]Watch mode is already off[/]")
            elif args.lower() == "status":
                # Show watch mode status
                if self.watch_mode:
                    self.console.print(f"[green]Watch mode: enabled[/]")
                    self.console.print(f"Goal: {self.watch_goal}")
                    self.console.print(f"Interval: {self.watch_interval}s")
                else:
                    self.console.print("[yellow]Watch mode: disabled[/]")
            else:
                # Enable watch mode with goal
                # First stop any existing watch thread to prevent multiple threads (thread-safe)
                thread_to_join = None
                with self.watch_lock:
                    if self.watch_thread and self.watch_thread.is_alive():
                        self.watch_mode = False
                        if self.watch_task and not self.watch_task.done():
                            try:
                                self.event_loop.call_soon_threadsafe(self.watch_task.cancel)
                            except RuntimeError:
                                pass  # Loop already closed
                        thread_to_join = self.watch_thread

                # Join outside lock (blocking operation)
                if thread_to_join:
                    thread_to_join.join(timeout=2.0)

                with self.watch_lock:
                    self.watch_mode = True
                    self.watch_goal = args
                    # Reset state for fresh analysis with new goal
                    self.previous_watch_context_hash = None
                    self.previous_watch_iteration_count = 0
                    self._start_watch_mode_thread()
                self.console.print(f"[green]✓[/] Watch mode enabled")
                self.console.print(f"Goal: {self.watch_goal}")
                self.console.print(f"Monitoring all terminals every {self.watch_interval}s...")
            return True

        elif cmd == "/squash":
            self.squash_context()
            return True

        elif cmd in ["/quit", "/exit"]:
            self._shutdown()  # Explicit cleanup before exit
            return False

        else:
            self.console.print(f"[red]Unknown command: {cmd}[/]")
            self.console.print("Type /help for available commands")
            return True

    def _process_tool_call(self, tool_call) -> ToolResult:
        """Process a single tool call and return the result.

        Handles: execute_in_terminal, send_keypress, capture_terminal, refresh_context
        Includes type validation for arguments and scope validation.
        """
        # Extract and normalize tool info (fixes case sensitivity issue)
        tool_name = (tool_call.name or "").lower().strip()
        tool_args = tool_call.arguments if isinstance(tool_call.arguments, dict) else {}
        tool_call_id = tool_call.tool_call_id

        # Helper for type-safe string extraction (fixes type validation issue)
        def get_str(key: str, default: str = "") -> str:
            val = tool_args.get(key, default)
            if not isinstance(val, str):
                return str(val) if val else default
            return val

        # Handle each tool type
        if tool_name == "execute_in_terminal":
            cmd = get_str("command")
            if not cmd:
                return ToolResult(
                    name=tool_call.name,  # Preserve original name for model
                    output="Error: No command provided",
                    tool_call_id=tool_call_id
                )

            executed, exec_content = self.execute_command(cmd)

            if executed:
                # Handle TUI screenshot vs regular text output
                screenshot_path = None
                result_attachments = []
                if isinstance(exec_content, tuple):
                    exec_text, screenshot_path = exec_content
                    if screenshot_path:
                        result_attachments.append(Attachment(path=screenshot_path))
                else:
                    exec_text = exec_content

                # Debug output
                self._debug("═══ Captured Content ═══")
                self._debug(f"UUID: {self.exec_terminal_uuid}")
                if screenshot_path:
                    self._debug("Type: Screenshot (TUI)")
                    self._debug(f"Screenshot path: {screenshot_path}")
                else:
                    self._debug("Type: Text output")
                    self._debug(f"Length: {len(exec_text)} chars")
                self._debug("═══════════════════════════════")

                return ToolResult(
                    name=tool_call.name,
                    output=f"Command executed: {cmd}\n\nOutput:\n{exec_text}",
                    attachments=result_attachments,
                    tool_call_id=tool_call_id
                )
            else:
                # User declined
                return ToolResult(
                    name=tool_call.name,
                    output=f"User declined to execute command: {cmd}",
                    tool_call_id=tool_call_id
                )

        elif tool_name == "send_keypress":
            kp = get_str("keypress")
            if not kp:
                return ToolResult(
                    name=tool_call.name,
                    output="Error: No keypress provided",
                    tool_call_id=tool_call_id
                )

            # execute_keypress returns True if executed, False if declined
            executed = self.execute_keypress(kp)

            if executed:
                return ToolResult(
                    name=tool_call.name,
                    output=f"Keypress sent: {kp}",
                    tool_call_id=tool_call_id
                )
            else:
                return ToolResult(
                    name=tool_call.name,
                    output=f"User declined to send keypress: {kp}",
                    tool_call_id=tool_call_id
                )

        elif tool_name == "capture_terminal":
            scope = get_str("scope", "exec")
            # Validate scope (fixes scope validation inconsistency)
            if scope not in {"exec", "all"}:
                scope = "exec"

            self.console.print(f"\n[cyan]Capturing screenshot ({scope})...[/]")

            try:
                result_attachments = []
                captured_info = []

                if scope == 'all':
                    terminals = self.plugin_dbus.get_terminals_in_same_window(self.chat_terminal_uuid)
                    chat_uuid_normalized = self._normalize_uuid(self.chat_terminal_uuid)
                    other_terminals = [t for t in terminals if self._normalize_uuid(t['uuid']) != chat_uuid_normalized]

                    for term in other_terminals:
                        screenshot_data = self.plugin_dbus.capture_terminal_screenshot(term['uuid'])
                        if screenshot_data and not screenshot_data.startswith('ERROR'):
                            image_bytes = base64.b64decode(screenshot_data)
                            temp_path = os.path.join(tempfile.gettempdir(), f"sidechat_screenshot_{uuid.uuid4().hex[:12]}.png")
                            with open(temp_path, 'wb') as f:
                                f.write(image_bytes)
                            self.screenshot_files.append(temp_path)
                            result_attachments.append(Attachment(path=temp_path))
                            captured_info.append(term.get('title', 'Terminal'))
                            self.console.print(f"[green]✓[/] Screenshot: {term.get('title', 'Terminal')}")
                else:
                    screenshot_data = self.plugin_dbus.capture_terminal_screenshot(self.exec_terminal_uuid)
                    if not screenshot_data or screenshot_data.startswith('ERROR'):
                        error_msg = screenshot_data if screenshot_data else "No data returned"
                        self.console.print(f"[red]Screenshot failed: {error_msg}[/]")
                        captured_info.append(f"Error: {error_msg}")
                    else:
                        image_bytes = base64.b64decode(screenshot_data)
                        temp_path = os.path.join(tempfile.gettempdir(), f"sidechat_screenshot_{uuid.uuid4().hex[:12]}.png")
                        with open(temp_path, 'wb') as f:
                            f.write(image_bytes)
                        self.screenshot_files.append(temp_path)
                        result_attachments.append(Attachment(path=temp_path))
                        captured_info.append("Exec terminal")
                        self.console.print(f"[green]✓[/] Screenshot captured")

                return ToolResult(
                    name=tool_call.name,
                    output=f"Captured screenshots: {', '.join(captured_info)}" if captured_info else "No screenshots captured",
                    attachments=result_attachments,
                    tool_call_id=tool_call_id
                )
            except Exception as e:
                self.console.print(f"[red]Screenshot error: {e}[/]")
                return ToolResult(
                    name=tool_call.name,
                    output=f"Screenshot error: {e}",
                    tool_call_id=tool_call_id
                )

        elif tool_name == "refresh_context":
            self.console.print("\n[cyan]Refreshing terminal context...[/]")
            try:
                # Clear cache to get fresh content
                try:
                    self.plugin_dbus.clear_cache()
                except Exception:
                    pass

                # Capture fresh context
                context_text, tui_attachments_refresh = self.capture_context(include_exec_output=True)
                result_attachments = []
                if tui_attachments_refresh:
                    result_attachments.extend(tui_attachments_refresh)

                if context_text or tui_attachments_refresh:
                    tui_info = f" + {len(tui_attachments_refresh)} TUI screenshot(s)" if tui_attachments_refresh else ""
                    self.console.print(f"[green]✓[/] Context refreshed ({len(context_text)} chars{tui_info})")

                    return ToolResult(
                        name=tool_call.name,
                        output=f"Refreshed terminal context:\n\n{context_text}",
                        attachments=result_attachments,
                        tool_call_id=tool_call_id
                    )
                else:
                    self.console.print("[yellow]No terminal content captured[/]")
                    return ToolResult(
                        name=tool_call.name,
                        output="No terminal content captured",
                        tool_call_id=tool_call_id
                    )
            except Exception as e:
                self.console.print(f"[red]Context refresh error: {e}[/]")
                return ToolResult(
                    name=tool_call.name,
                    output=f"Context refresh error: {e}",
                    tool_call_id=tool_call_id
                )

        else:
            # Unknown tool - shouldn't happen with our defined tools
            self.console.print(f"[yellow]Unknown tool: {tool_call.name}[/]")
            return ToolResult(
                name=tool_call.name,
                output=f"Unknown tool: {tool_call.name}",
                tool_call_id=tool_call_id
            )

    def run(self):
        """Main REPL loop with health checks"""
        # Connect to Terminator
        self._connect_to_terminator()

        # Setup terminals
        self.setup_terminals()

        # Display welcome message
        self.console.print(Panel.fit(
            f"""[bold green]Terminator Sidechat Started[/]

Model: [cyan]{self.model_name}[/]

[bold]Commands:[/]
Type /help for slash commands
Type 'exit' or 'quit' to exit
Type !multi to enter multiple lines, then !end to finish
Type !fragment <name> [...] to insert fragments
""",
            title="llm-sidechat",
            border_style="green"
        ))

        # Main REPL loop with periodic health checks
        check_counter = 0

        # Multi-line input state
        in_multi = False
        accumulated_lines = []
        end_token = "!end"

        try:
            while True:
                # Periodic health check every 10 iterations
                check_counter += 1
                if check_counter >= 10:
                    # Check plugin availability
                    if not self._check_plugin_available():
                        self.console.print("[yellow]Plugin unavailable, attempting reconnect...[/]")
                        if not self._reconnect_plugin():
                            self.console.print("[red]Plugin reconnection failed. Please restart sidechat.[/]")
                            break

                    # Check D-Bus connection
                    if not self._check_dbus_connection():
                        self.console.print("[yellow]D-Bus disconnected, attempting reconnect...[/]")
                        if not self._reconnect_dbus():
                            self.console.print("[red]D-Bus reconnection failed. Please restart sidechat.[/]")
                            break

                    check_counter = 0

                # Get user input (change prompt based on mode)
                try:
                    if in_multi:
                        # Multi-line mode - simple dim prompt
                        # Use \001...\002 to mark non-printable ANSI sequences for readline
                        # This fixes cursor positioning when input wraps to next line
                        user_input = input("\001\033[2m\002...\001\033[0m\002 ")
                    else:
                        # Regular mode - cyan > prompt
                        # Use \001...\002 to mark non-printable ANSI sequences for readline
                        # This fixes cursor positioning when input wraps to next line
                        user_input = input("\n\001\033[1;36m\002>\001\033[0m\002 ").strip()
                except (KeyboardInterrupt, EOFError):
                    self.console.print("\n[yellow]Exiting...[/]")
                    break

                # Handle !multi command (start multi-line mode)
                if user_input.startswith("!multi"):
                    in_multi = True
                    bits = user_input.split()
                    if len(bits) > 1:
                        end_token = f"!end {' '.join(bits[1:])}"
                    else:
                        end_token = "!end"
                    self.console.print(f"[dim]Multi-line mode. Type '{end_token}' to finish[/]")
                    continue

                # Handle multi-line input accumulation
                if in_multi:
                    if user_input == end_token:
                        # Join accumulated lines and process
                        user_input = "\n".join(accumulated_lines)
                        accumulated_lines = []
                        in_multi = False
                    else:
                        # Accumulate this line
                        accumulated_lines.append(user_input)
                        continue

                if not user_input:
                    continue

                # Handle exit/quit commands (like llm chat mode)
                if user_input in ("exit", "quit"):
                    self.console.print("\n[yellow]Exiting...[/]")
                    self._shutdown()
                    break

                # Handle slash commands
                if user_input.startswith('/'):
                    should_continue = self.handle_slash_command(user_input)
                    if not should_continue:
                        break
                    continue

                # Check if we need to squash context (before lock to avoid holding it during squash)
                self.check_and_squash_context()

                # Send to AI with streaming
                # Pass system prompt on first interaction or when conversation is empty
                response_text = ""
                stream_success = False

                try:
                    self.console.print("\n[bold green]llm[/]")

                    # Thread-safe context capture AND conversation access
                    # Extended lock scope fixes race condition with watch mode
                    with self.watch_lock:
                        # Clear plugin cache inside lock to ensure atomic operation
                        try:
                            self.plugin_dbus.clear_cache()
                        except Exception:
                            pass  # Ignore if clear_cache not available

                        # Simple snapshot capture (no stability detection)
                        # Works better for TUI applications and provides instant feedback
                        # Returns (context_text, tui_attachments) tuple for TUI screenshot support
                        context, tui_attachments = self.capture_context(include_exec_output=True)

                        # Process fragments if present
                        processed_input, fragments = self.process_fragments(user_input)

                        # Combine user fragments with TUI screenshot attachments
                        all_attachments = fragments + tui_attachments

                        # Build prompt with context
                        if context:
                            full_prompt = f"""{processed_input}

[Current terminal context]
{context}
"""
                        else:
                            full_prompt = processed_input

                        # Pass system prompt if this is the first interaction
                        # Also pass attachments (user fragments + TUI screenshots)
                        # Include tools for structured output (schema validation)
                        if len(self.conversation.responses) == 0:
                            response = self.conversation.prompt(
                                full_prompt,
                                system=self.system_prompt,
                                attachments=all_attachments,
                                tools=SIDECHAT_TOOLS
                            )
                        else:
                            response = self.conversation.prompt(
                                full_prompt,
                                attachments=all_attachments,
                                tools=SIDECHAT_TOOLS
                            )

                        # Consume response INSIDE lock to prevent race condition with watch mode
                        # This trades streaming display for thread safety - response shows all at once
                        # instead of character-by-character, but prevents potential corruption if
                        # watch thread calls conversation.prompt() while we're iterating
                        response_text = response.text()

                        # Extract tool calls from the response (structured output)
                        tool_calls = list(response.tool_calls())

                    # Display the response OUTSIDE lock (already consumed)
                    # Note: With tool calling, the model's text output is separate from tool calls
                    if response_text.strip():
                        self.console.print(Markdown(response_text))

                    stream_success = True

                except Exception as e:
                    print()  # Ensure newline even on error
                    self.console.print(f"\n[red]Streaming error: {e}[/]")
                    self.console.print("[yellow]Response may be incomplete. Please try again.[/]")
                    # Don't process commands or update conversation on stream failure
                    continue

                # Only process tool calls if streaming succeeded
                if stream_success:
                    try:
                        # Process tool calls (structured output from model)
                        if tool_calls:
                            if self.debug:
                                self.console.print(f"\n[cyan]Processing {len(tool_calls)} tool call(s)[/]")

                            # Collect tool results for sending back to model
                            tool_results = []

                            for i, tool_call in enumerate(tool_calls, 1):
                                if len(tool_calls) > 1:
                                    self.console.print(f"\n[bold]Tool {i}/{len(tool_calls)}: {tool_call.name}[/]")
                                tool_results.append(self._process_tool_call(tool_call))

                            # After processing all tool calls, send results back to model
                            # Loop to handle multi-round tool calling (max 5 iterations for safety)
                            MAX_TOOL_ITERATIONS = 5
                            iteration = 0

                            while tool_results and iteration < MAX_TOOL_ITERATIONS:
                                iteration += 1
                                if self.debug:
                                    self.console.print(f"\n[dim]Sending {len(tool_results)} tool result(s) to model...[/]")

                                with self.watch_lock:
                                    # Continue conversation with tool results
                                    followup_response = self.conversation.prompt(
                                        "",  # Empty prompt - tool results drive the continuation
                                        tools=SIDECHAT_TOOLS,
                                        tool_results=tool_results
                                    )
                                    followup_text = followup_response.text()

                                    # Check if the model made more tool calls
                                    more_tool_calls = list(followup_response.tool_calls())

                                # Display the AI's response
                                if followup_text.strip() and followup_text.strip().lower() not in ["ok", "okay", "done"]:
                                    self.console.print("\n[bold green]llm[/]")
                                    self.console.print(Markdown(followup_text))

                                # Process additional tool calls if any
                                if not more_tool_calls:
                                    break

                                if self.debug:
                                    self.console.print(f"\n[cyan]Processing {len(more_tool_calls)} additional tool call(s) (round {iteration + 1})[/]")
                                tool_results = []

                                for j, tool_call in enumerate(more_tool_calls, 1):
                                    if len(more_tool_calls) > 1:
                                        self.console.print(f"\n[bold]Tool {j}/{len(more_tool_calls)}: {tool_call.name}[/]")
                                    tool_results.append(self._process_tool_call(tool_call))

                            # Warn if max iterations reached and model still wants more
                            if iteration >= MAX_TOOL_ITERATIONS and more_tool_calls:
                                self.console.print(f"\n[yellow]Max tool iterations ({MAX_TOOL_ITERATIONS}) reached. Model requested {len(more_tool_calls)} more tool call(s). Please continue the conversation.[/]")

                    except Exception as e:
                        self.console.print(f"\n[red]Tool execution error: {e}[/]")

        finally:
            # Unified cleanup - handles all resources
            self._shutdown()


def main():
    """Entry point"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Terminator AI Sidechat - Terminal assistant for pair programming"
    )
    parser.add_argument(
        'model',
        nargs='?',
        help='LLM model to use (default: azure/gpt-4.1-mini)'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Enable debug output for troubleshooting'
    )
    parser.add_argument(
        '--capture-timeout',
        type=float,
        default=3.0,
        metavar='SECS',
        help='Maximum wait time for command output capture (default: 3.0 seconds)'
    )
    args = parser.parse_args()

    session = TerminatorSidechatSession(
        model_name=args.model,
        debug=args.debug,
        capture_timeout=args.capture_timeout
    )
    session.run()


if __name__ == "__main__":
    main()
